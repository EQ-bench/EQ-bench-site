{
    "judge_model": "google/gemini-pro-1.5",
    "start_time": "2025-01-31T20:38:39.813952",
    "status": "completed",
    "samples_file": "data/judgemark_v2.1_samples.json",
    "prompts_file": "data/judge_prompts.json",
    "end_time": "2025-01-31T21:11:24.689711",
    "raw_score_distribution": {
        "count": 2040,
        "min": 1.47,
        "max": 9.41,
        "mean": 5.342,
        "median": 5.25,
        "stdev": 1.538,
        "p10": 3.379,
        "p25": 4.12,
        "p75": 6.52,
        "p90": 7.462
    },
    "calibration_config": {
        "method": "piecewise_landmark",
        "in_landmarks": [
            1.47,
            4.12,
            5.25,
            6.52,
            9.41
        ],
        "out_landmarks": [
            0,
            3,
            5,
            7,
            10
        ]
    },
    "calibrated_score_distribution": {
        "count": 2040,
        "min": 0.0,
        "max": 10.0,
        "mean": 5.021,
        "median": 5.0,
        "stdev": 2.216,
        "p10": 2.161,
        "p25": 3.0,
        "p75": 7.0,
        "p90": 7.978
    },
    "raw_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.45675,
            "median": 6.355,
            "stdev": 0.9566899891261106,
            "ci95": 0.17117355794402267,
            "min": 4.29,
            "max": 9.04,
            "length_correlation": 0.06739834906640998
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 5.1459166666666665,
            "median": 5.055,
            "stdev": 1.0333648194805434,
            "ci95": 0.1848924257755042,
            "min": 2.8,
            "max": 7.78,
            "length_correlation": 0.09376669102809122
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.022666666666667,
            "median": 6.09,
            "stdev": 1.0118696675410503,
            "ci95": 0.1810464551080455,
            "min": 3.96,
            "max": 8.19,
            "length_correlation": 0.18360846065316436
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.6273333333333335,
            "median": 6.56,
            "stdev": 0.776914532285367,
            "ci95": 0.13900764743151525,
            "min": 4.71,
            "max": 8.7,
            "length_correlation": -0.17529415034801257
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.559333333333333,
            "median": 5.61,
            "stdev": 0.8646558875769994,
            "ci95": 0.15470656780782066,
            "min": 3.36,
            "max": 7.52,
            "length_correlation": -0.02596803774518546
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.621333333333333,
            "median": 4.61,
            "stdev": 1.0714232530213472,
            "ci95": 0.19170194354301662,
            "min": 2.71,
            "max": 7.52,
            "length_correlation": -0.3158240459917356
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 4.132,
            "median": 4.055,
            "stdev": 0.8063848154499409,
            "ci95": 0.14428055012751384,
            "min": 2.46,
            "max": 6.78,
            "length_correlation": -0.13683517516121996
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 3.867916666666667,
            "median": 3.93,
            "stdev": 0.8871338949781187,
            "ci95": 0.1587283936302653,
            "min": 1.86,
            "max": 7.82,
            "length_correlation": -0.1150135716260092
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 3.4509166666666666,
            "median": 3.37,
            "stdev": 0.8186194525683159,
            "ci95": 0.14646960446017102,
            "min": 1.54,
            "max": 6.07,
            "length_correlation": -0.025303384931609225
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.672,
            "median": 4.64,
            "stdev": 1.0247882339145722,
            "ci95": 0.18335787991109134,
            "min": 2.22,
            "max": 7.3,
            "length_correlation": -0.1701556109712837
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 4.9565,
            "median": 4.9399999999999995,
            "stdev": 0.9731596723555491,
            "ci95": 0.17412035817046714,
            "min": 2.63,
            "max": 7.39,
            "length_correlation": 0.15814402948048664
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 6.899333333333334,
            "median": 6.8,
            "stdev": 0.8335463705281959,
            "ci95": 0.14914036895585175,
            "min": 5.38,
            "max": 8.81,
            "length_correlation": -0.14663741831734595
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.40625,
            "median": 5.4,
            "stdev": 1.2145172727805698,
            "ci95": 0.2173047122153139,
            "min": 2.18,
            "max": 7.86,
            "length_correlation": -0.07378669812274645
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.129083333333333,
            "median": 7.07,
            "stdev": 0.7970987263518998,
            "ci95": 0.14261905797398056,
            "min": 4.39,
            "max": 8.81,
            "length_correlation": 0.19707355763944392
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 7.6505833333333335,
            "median": 7.805,
            "stdev": 0.8585940195902779,
            "ci95": 0.15362196200775172,
            "min": 5.21,
            "max": 9.41,
            "length_correlation": 0.09221981764306753
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 4.071916666666667,
            "median": 4.125,
            "stdev": 0.7118189457190598,
            "ci95": 0.1273605691870923,
            "min": 2.07,
            "max": 6.16,
            "length_correlation": -0.06049121489838304
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 4.14725,
            "median": 4.11,
            "stdev": 0.9321430648121086,
            "ci95": 0.1667815559170667,
            "min": 1.47,
            "max": 6.61,
            "length_correlation": -0.23578905901393835
        }
    },
    "calibrated_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.7025622779905065,
            "median": 6.740157480314961,
            "stdev": 1.2633324817995426,
            "ci95": 0.22603886131746076,
            "min": 3.3008849557522124,
            "max": 9.615916955017301,
            "length_correlation": 0.06108825476476909
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 4.757068347516921,
            "median": 4.654867256637168,
            "stdev": 1.6167740820036298,
            "ci95": 0.28927758746701115,
            "min": 1.5056603773584902,
            "max": 8.30795847750865,
            "length_correlation": 0.0959912860638559
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.0790247422687385,
            "median": 6.3228346456692925,
            "stdev": 1.4854725462919922,
            "ci95": 0.26578476190519534,
            "min": 2.8188679245283015,
            "max": 8.73356401384083,
            "length_correlation": 0.19297684686523225
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.9714273876802855,
            "median": 7.041522491349481,
            "stdev": 0.9893821294213525,
            "ci95": 0.1770229240236797,
            "min": 4.044247787610619,
            "max": 9.262975778546712,
            "length_correlation": -0.16184775390151243
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.432322997146495,
            "median": 5.5669291338582685,
            "stdev": 1.3662821846074376,
            "ci95": 0.24445890032613085,
            "min": 2.1396226415094333,
            "max": 8.038062283737023,
            "length_correlation": -0.0073189114180971775
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 3.981926432570154,
            "median": 3.867256637168142,
            "stdev": 1.6290988381978448,
            "ci95": 0.29148276614823,
            "min": 1.4037735849056603,
            "max": 8.038062283737023,
            "length_correlation": -0.32973088718695176
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 3.203972015709365,
            "median": 2.9264150943396228,
            "stdev": 1.189218498129576,
            "ci95": 0.21277818709447477,
            "min": 1.120754716981132,
            "max": 7.269896193771627,
            "length_correlation": -0.13831027788246358
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 2.833387402988724,
            "median": 2.7849056603773583,
            "stdev": 1.2116177704709372,
            "ci95": 0.21678592542727604,
            "min": 0.4415094339622642,
            "max": 8.349480968858131,
            "length_correlation": -0.11059386469309283
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 2.3136614721039312,
            "median": 2.1509433962264146,
            "stdev": 1.0617567566287052,
            "ci95": 0.1899723878884278,
            "min": 0.07924528301886798,
            "max": 6.291338582677167,
            "length_correlation": -0.016898629463149108
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.043704948035364,
            "median": 3.920353982300884,
            "stdev": 1.5561799844945197,
            "ci95": 0.2784359278082581,
            "min": 0.849056603773585,
            "max": 7.809688581314879,
            "length_correlation": -0.18393639528233582
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 4.47816057088172,
            "median": 4.451327433628318,
            "stdev": 1.5275268020276511,
            "ci95": 0.2733092229769957,
            "min": 1.313207547169811,
            "max": 7.903114186851211,
            "length_correlation": 0.15954726013025244
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 7.301139098529639,
            "median": 7.290657439446367,
            "stdev": 0.9912370461964847,
            "ci95": 0.177354810745291,
            "min": 5.2047244094488185,
            "max": 9.377162629757786,
            "length_correlation": -0.1442705649067285
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.171055056320192,
            "median": 5.2362204724409445,
            "stdev": 1.818248040397606,
            "ci95": 0.32532585250934226,
            "min": 0.8037735849056605,
            "max": 8.391003460207614,
            "length_correlation": -0.058248248737776995
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.579426637337725,
            "median": 7.570934256055364,
            "stdev": 0.9537245468741968,
            "ci95": 0.1706429730033343,
            "min": 3.4778761061946897,
            "max": 9.377162629757786,
            "length_correlation": 0.20152093377867142
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 8.146042911460944,
            "median": 8.333910034602077,
            "stdev": 0.9525577898603413,
            "ci95": 0.17043421368569975,
            "min": 4.929203539823009,
            "max": 10.0,
            "length_correlation": 0.09096786154057282
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 3.0955424161268534,
            "median": 3.012038737685757,
            "stdev": 1.0104794762582463,
            "ci95": 0.18079771832726482,
            "min": 0.6792452830188677,
            "max": 6.433070866141733,
            "length_correlation": -0.04948010723332635
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 3.261082645346825,
            "median": 2.988679245283019,
            "stdev": 1.3567508978431926,
            "ci95": 0.24275353674360722,
            "min": 0.0,
            "max": 7.093425605536333,
            "length_correlation": -0.22420584040948577
        }
    },
    "raw_cross_model_stats": {
        "anova_f": 226.12339370157167,
        "anova_p": 0.0,
        "kw_stat": 1310.3617666390985,
        "kw_p": 2.9875383952671e-269,
        "std_dev_across_models": 1.2311401970664255,
        "pearson_r": 0.9696142312744211,
        "kendall_tau": 0.9088235294117647,
        "normalized_components": {
            "pearson_r": 0.8987141042480705,
            "kendall_tau": 0.8986928104575164,
            "anova_f": 0.6460668391473476,
            "kw_stat": 0.8735745110927323,
            "std_dev": 0.5596091804847388,
            "ci99_overlap_magnitude_sum_norm": 0.7628859307285474,
            "raw_score_range_norm": 0.5249583333333334,
            "kendall_tau_bootstrapped": 0.8874166666666665
        }
    },
    "calibrated_cross_model_stats": {
        "anova_f": 232.54237340306946,
        "anova_p": 0.0,
        "kw_stat": 1310.3617666390985,
        "kw_p": 2.9875383952671e-269,
        "std_dev_across_models": 1.7834886879567406,
        "pearson_r": 0.9653996019259271,
        "kendall_tau": 0.9117647058823529,
        "normalized_components": {
            "pearson_r": 0.8846653397530904,
            "kendall_tau": 0.9019607843137255,
            "anova_f": 0.664406781151627,
            "kw_stat": 0.8735745110927323,
            "std_dev": 0.810676676343973,
            "ci99_overlap_magnitude_sum_norm": 0.6553828627814067,
            "calibrated_score_range_norm": 0.7290476799196266,
            "kendall_tau_bootstrapped": 0.8908284313725489
        }
    },
    "separability_metrics": {
        "raw": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__claude-3-5-sonnet-20240620": true,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": false,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": false,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__gemma-7b-it": true,
                "gemma-7b-it__gemma-2b-it": false
            },
            "adjacent_overlap_fraction": 0.75,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.06247931136389795,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": 0.3453947562289512,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.2960255900791333,
                "gemini-1.5-pro-001__claude-3-5-sonnet-20240620": 0.44087623673026144,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.26024725155127904,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.19853590787723796,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.5802617352898753,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": 0.5325170548097153,
                "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.5183044934634644,
                "c4ai-command-r-08-2024__Mixtral-8x22B-Instruct-v0.1": 0.4201961130343186,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.6886879893310143,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.23259444938200247,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.5688399014550103,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.47540224461007474,
                "gpt-3.5-turbo-0125__gemma-7b-it": 0.3599665820256597,
                "gemma-7b-it__gemma-2b-it": 0.184636183825873
            },
            "ci99_overlap_magnitude_sum": 6.16496580105777,
            "ci99_overlap_scale_factor": 1.5,
            "average_cohens_d_adjacent": 0.2878473429869349,
            "emd": {
                "average": 1.5004718137254907,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 1.3108333333333335,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.43408333333333327,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.23174999999999996,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 0.8974166666666669,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 1.8354166666666667,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 2.32475,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 2.5888333333333335,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 3.0058333333333334,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 1.78475,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 1.5002500000000003,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.4464166666666667,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 1.0505,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.6761666666666666,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 1.193833333333333,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 2.384833333333333,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 2.3095,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 0.87675,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 1.4814166666666666,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.42258333333333326,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.5245833333333333,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 1.0139166666666666,
                    "claude-3-haiku-20240307__gemma-7b-it": 1.2786666666666666,
                    "claude-3-haiku-20240307__gemma-2b-it": 1.6949999999999998,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.47391666666666665,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.18941666666666668,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 1.7534166666666666,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.33666666666666656,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 1.9831666666666667,
                    "claude-3-haiku-20240307__DeepSeek-R1": 2.504666666666667,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 1.0739999999999998,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.9986666666666665,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.6046666666666667,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.46333333333333343,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 1.4013333333333333,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 1.8906666666666665,
                    "claude-3-opus-20240229__gemma-7b-it": 2.15475,
                    "claude-3-opus-20240229__gemma-2b-it": 2.5717499999999998,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 1.3506666666666667,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 1.0661666666666667,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.8766666666666666,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.6164166666666666,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 1.1064166666666666,
                    "claude-3-opus-20240229__DeepSeek-R1": 1.6279166666666667,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 1.9507499999999998,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 1.8754166666666663,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 1.068,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 2.006,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 2.4953333333333334,
                    "gemini-1.5-pro-001__gemma-7b-it": 2.7594166666666666,
                    "gemini-1.5-pro-001__gemma-2b-it": 3.1764166666666664,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 1.9553333333333334,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 1.6708333333333334,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.2725,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 1.2210833333333333,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.51125,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.02325,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 2.555416666666667,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 2.480083333333334,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.938,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 1.4273333333333333,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 1.6964166666666665,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 2.108416666666667,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.8873333333333333,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.6028333333333333,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 1.34,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.31791666666666674,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 1.56975,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 2.0912499999999996,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 1.4874166666666666,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 1.4120833333333334,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.49716666666666665,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 0.7584166666666667,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.1704166666666664,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.1333333333333333,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.33866666666666667,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 2.278,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.8015833333333333,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 2.50775,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 3.02925,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.55175,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.4740833333333333,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.2819166666666666,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.6810833333333335,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.5473333333333332,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.8244999999999999,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 2.767333333333333,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 1.2832499999999998,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 2.997083333333333,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 3.518583333333334,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.12225000000000003,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.1409166666666667,
                    "gemma-7b-it__gemma-2b-it": 0.41700000000000004,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 0.8127500000000001,
                    "gemma-7b-it__c4ai-command-r-08-2024": 1.0957499999999998,
                    "gemma-7b-it__gemini-1.5-pro-002": 3.031416666666667,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 1.5383333333333336,
                    "gemma-7b-it__gpt-4o-2024-11-20": 3.2611666666666665,
                    "gemma-7b-it__DeepSeek-R1": 3.7826666666666675,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.2583333333333334,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.3128333333333333,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 1.2210833333333335,
                    "gemma-2b-it__c4ai-command-r-08-2024": 1.5055833333333335,
                    "gemma-2b-it__gemini-1.5-pro-002": 3.448416666666667,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 1.955333333333333,
                    "gemma-2b-it__gpt-4o-2024-11-20": 3.6781666666666664,
                    "gemma-2b-it__DeepSeek-R1": 4.199666666666667,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.621,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.6975,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.29316666666666663,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 2.227333333333333,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.73675,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 2.4570833333333333,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 2.9785833333333334,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.6000833333333333,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.52475,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 1.9428333333333332,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.4899166666666667,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 2.1725833333333333,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 2.6940833333333334,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.8845833333333333,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.80925,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 1.4930833333333333,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.2629166666666667,
                    "gemini-1.5-pro-002__DeepSeek-R1": 0.7540833333333332,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 2.8274166666666662,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 2.752083333333333,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 1.7228333333333334,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 2.2443333333333335,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 1.3344999999999994,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 1.2601666666666667,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.5215,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 3.0571666666666664,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 2.9818333333333333,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 3.5786666666666673,
                    "DeepSeek-R1__databricks/dbrx-instruct": 3.5033333333333334,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.20499999999999996
                }
            },
            "average_ci95": 0.16390080059802886,
            "modulated_ci95": 0.6862741198212221
        },
        "calibrated": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__claude-3-5-sonnet-20240620": true,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": true,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": false,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__gemma-7b-it": true,
                "gemma-7b-it__gemma-2b-it": true
            },
            "adjacent_overlap_fraction": 0.875,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.10574848014639837,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": 0.4077197741636862,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.3688723864030923,
                "gemini-1.5-pro-001__claude-3-5-sonnet-20240620": 0.5256897559906655,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.3459933578046446,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.3591405332901747,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.8619475666244458,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": 0.7975797841199803,
                "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.8301184418329992,
                "c4ai-command-r-08-2024__Mixtral-8x22B-Instruct-v0.1": 0.6531984543095084,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 1.0617010298409935,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.33229513421168644,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.838898402256059,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.6674257705879789,
                "gpt-3.5-turbo-0125__gemma-7b-it": 0.5216008033374013,
                "gemma-7b-it__gemma-2b-it": 0.28211589276371374
            },
            "ci99_overlap_magnitude_sum": 8.960045567683427,
            "ci99_overlap_scale_factor": 1.5,
            "average_cohens_d_adjacent": 0.2869415430147405,
            "emd": {
                "average": 2.1776006323336015,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 1.945493930473585,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.6235375357217676,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.3323599193783601,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 1.2702392808440108,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 2.720635845420352,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 3.498590262281141,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 3.869174875001782,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 4.388900805886575,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 2.6588573299551417,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 2.224401707108787,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.602556059293458,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 1.5315072216703147,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.8808435981015434,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 1.443480633470438,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 3.6070198618636526,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 3.4414796326436816,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 1.3219563947518171,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 2.2143590401633637,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.6847702205638303,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.7751419149467674,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 1.553096331807556,
                    "claude-3-haiku-20240307__gemma-7b-it": 1.9243729860506884,
                    "claude-3-haiku-20240307__gemma-2b-it": 2.44340687541299,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.7133633994815572,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.2789077766352022,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 2.5440707510127174,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.5015711692028919,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 2.8223582898208033,
                    "claude-3-haiku-20240307__DeepSeek-R1": 3.3889745639440227,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 1.6615259313900677,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 1.4959857021700964,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.8924026454115466,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.646701745122243,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 2.0970983096985853,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 2.8750527265593733,
                    "claude-3-opus-20240229__gemma-7b-it": 3.245637339280014,
                    "claude-3-opus-20240229__gemma-2b-it": 3.7653632701648068,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 2.0353197942333745,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 1.6008641713870198,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 1.2221143562609005,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.907969685948547,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 1.5004018950689857,
                    "claude-3-opus-20240229__DeepSeek-R1": 2.0670181691922056,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 2.983482326141885,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 2.817942096921914,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 1.5391043905337898,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 2.989500955110131,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 3.76745537197092,
                    "gemini-1.5-pro-001__gemma-7b-it": 4.138039984691561,
                    "gemini-1.5-pro-001__gemma-2b-it": 4.657765915576354,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 2.927722439644921,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 2.493266816798566,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.3302307419912224,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 1.8003723313600932,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.6248134089494746,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.174615523780659,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 3.875884971553432,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 3.7103447423334606,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 1.4503965645763417,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 2.2283509814371305,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 2.604125905576457,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 3.118661525042564,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 1.3886180491111315,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.9541624262647763,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 1.8688161013831435,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.4526819033543442,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 2.1471036401912293,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 2.7137199143144484,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 2.336780581019642,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 2.1712403517996703,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.7868223413890905,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 1.153729341000115,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.6682649604662225,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.18626617247733057,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.49999270722192635,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 3.319212665959485,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 1.2079965482783397,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 3.59750020476757,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 4.16411647889079,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.8890255258772626,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.720843787223329,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.38909672344728496,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.8903105436054342,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.8480348191184516,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 1.274188555172354,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 4.097167082820274,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 1.9772717198561092,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 4.375454621628359,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 4.942070895751579,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.17987001812762232,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.20285792601290373,
                    "gemma-7b-it__gemma-2b-it": 0.5197259308847926,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 1.2193140848390278,
                    "gemma-7b-it__c4ai-command-r-08-2024": 1.6522126142597775,
                    "gemma-7b-it__gemini-1.5-pro-002": 4.467751695540915,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 2.337667653331468,
                    "gemma-7b-it__gpt-4o-2024-11-20": 4.746039234349,
                    "gemma-7b-it__DeepSeek-R1": 5.31265550847222,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.33594302223643513,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.4651389212375373,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 1.730043475931433,
                    "gemma-2b-it__c4ai-command-r-08-2024": 2.1644990987777875,
                    "gemma-2b-it__gemini-1.5-pro-002": 4.987477626425708,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 2.8573935842162603,
                    "gemma-2b-it__gpt-4o-2024-11-20": 5.265765165233792,
                    "gemma-2b-it__DeepSeek-R1": 5.832381439357013,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.7818809440229222,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.948741927959875,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.4445256443704812,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 3.2574341504942748,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 1.130180296964073,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 3.53572168930236,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 4.10233796342558,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.9481625319085105,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.7826223026885392,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 2.82297852764792,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.7383661835516802,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 3.101266066456005,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 3.667882340579225,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 1.3826181547548653,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 1.2170779255348942,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 2.130084042209447,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.331265267956121,
                    "gemini-1.5-pro-002__DeepSeek-R1": 0.8494958274250688,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 4.205596682402786,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 4.040056453182814,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 2.408371581017533,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 2.9749878551407525,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 2.0757013194386214,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 1.9112931656903478,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.5666162741232199,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 4.48388422121087,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 4.318343991990899,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 5.050500495334091,
                    "DeepSeek-R1__databricks/dbrx-instruct": 4.88496026611412,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.3125452940610689
                }
            },
            "average_ci95": 0.23133273867045173,
            "modulated_ci95": 0.5228726781059007
        }
    },
    "iteration_stability": {
        "raw": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.45675,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11373867464987941
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 5.1459166666666665,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11566156328799211
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.022666666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11597670982668115
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.6273333333333335,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.04618696906175058
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.559333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11946628999196562
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 4.621333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.10266362279037544
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 4.132,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14720790286756594
                },
                "gemma-7b-it": {
                    "mean_iter_score": 3.867916666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.010995579920030469
                },
                "gemma-2b-it": {
                    "mean_iter_score": 3.4509166666666666,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1734003075737372
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.672,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.25293875521336945
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 4.9565,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07738324538727133
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 6.899333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08443669555090096
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.40625,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.10128617323647339
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.129083333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.05111153381467711
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 7.6505833333333335,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1506708609298205
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 4.071916666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14579061279032282
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 4.14725,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.259124139061656
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8529411764705882,
                        "p_value": 2.3940311991296275e-08
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8970588235294118,
                        "p_value": 1.2313901628307946e-09
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    }
                },
                "average_kendall_tau": 0.9235294117647058
            },
            "randomized_average_kendall_tau_by_item": 0.9324499999999999
        },
        "calibrated": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.7025622779905065,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1558521806149345
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 4.757068347516921,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.17895964214026572
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.0790247422687385,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2040952693429632
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.9714273876802855,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.0581001142989017
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.432322997146495,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.194030483336064
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 3.981926432570154,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.16196307008626673
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 3.2039720157093656,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.22979563841316092
                },
                "gemma-7b-it": {
                    "mean_iter_score": 2.833387402988724,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.034955234233284296
                },
                "gemma-2b-it": {
                    "mean_iter_score": 2.3136614721039312,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2194946189083187
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.043704948035364,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.40182802264445955
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 4.47816057088172,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11662017111640581
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 7.30113909852964,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.0926021123193687
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.171055056320192,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.17355253450537783
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.579426637337725,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.054474494162977255
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 8.146042911460944,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.16535340685439687
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 3.095542416126854,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.19339925001180264
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 3.261082645346825,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3686235349225796
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8676470588235293,
                        "p_value": 9.575975226992579e-09
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8970588235294118,
                        "p_value": 1.2313901628307946e-09
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    }
                },
                "average_kendall_tau": 0.9235294117647058
            },
            "randomized_average_kendall_tau_by_item": 0.9344970588235293
        }
    },
    "raw_score_range": 4.199666666666667,
    "final_judgemark_score_elements_raw": {
        "norm_stability_between_iterations": 0.8874166666666665,
        "norm_correlation_with_lmsys_arena": 0.8986928104575164,
        "norm_std_dev_between_models": 0.5596091804847388,
        "norm_kruskall_wallis": 0.8735745110927323,
        "norm_ci99_adjacent_overlap": 0.7628859307285474,
        "norm_score_range": 0.5249583333333334,
        "norm_intra_model_ci95": 0.6862741198212221,
        "norm_earth_movers_distance": 0.37511795343137266
    },
    "final_judgemark_score_raw": 0.7179538049531358,
    "calibrated_score_range": 5.832381439357013,
    "final_judgemark_score_elements_calibrated": {
        "norm_stability_between_iterations": 0.8908284313725489,
        "norm_correlation_with_lmsys_arena": 0.9019607843137255,
        "norm_std_dev_between_models": 0.810676676343973,
        "norm_kruskall_wallis": 0.8735745110927323,
        "norm_ci99_adjacent_overlap": 0.6553828627814067,
        "norm_score_range": 0.7290476799196266,
        "norm_intra_model_ci95": 0.5228726781059007,
        "norm_earth_movers_distance": {
            "pearson_r": 0.8846653397530904,
            "kendall_tau": 0.9019607843137255,
            "anova_f": 0.664406781151627,
            "kw_stat": 0.8735745110927323,
            "std_dev": 0.810676676343973,
            "ci99_overlap_magnitude_sum_norm": 0.6553828627814067,
            "calibrated_score_range_norm": 0.7290476799196266,
            "kendall_tau_bootstrapped": 0.8908284313725489
        }
    },
    "final_judgemark_score": 0.7583487099840501
}