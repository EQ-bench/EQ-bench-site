{
    "judge_model": "qwen/qwen-plus",
    "start_time": "2025-02-02T11:50:10.819633",
    "status": "completed",
    "samples_file": "data/judgemark_v2.1_samples.json",
    "prompts_file": "data/judge_prompts.json",
    "errors": [
        {
            "model": "claude-3-haiku-20240307",
            "iteration": "1",
            "item_id": "38",
            "error": "'choices'"
        },
        {
            "model": "claude-3-opus-20240229",
            "iteration": "3",
            "item_id": "41",
            "error": "'choices'"
        },
        {
            "model": "claude-3-opus-20240229",
            "iteration": "4",
            "item_id": "26",
            "error": "'choices'"
        },
        {
            "model": "claude-3-opus-20240229",
            "iteration": "4",
            "item_id": "27",
            "error": "'choices'"
        },
        {
            "model": "claude-3-opus-20240229",
            "iteration": "4",
            "item_id": "28",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "1",
            "item_id": "26",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "1",
            "item_id": "27",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "1",
            "item_id": "36",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "1",
            "item_id": "37",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "1",
            "item_id": "38",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "1",
            "item_id": "41",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "36",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "37",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "38",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "41",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "42",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "43",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "2",
            "item_id": "44",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "2",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "27",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "28",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "29",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "30",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "31",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "3",
            "item_id": "32",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "4",
            "item_id": "31",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "4",
            "item_id": "32",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "4",
            "item_id": "44",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "5",
            "item_id": "2",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "5",
            "item_id": "6",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "5",
            "item_id": "9",
            "error": "'choices'"
        },
        {
            "model": "gemini-1.5-pro-001",
            "iteration": "5",
            "item_id": "10",
            "error": "'choices'"
        },
        {
            "model": "Llama-2-13b-chat-hf",
            "iteration": "3",
            "item_id": "20",
            "error": "'choices'"
        },
        {
            "model": "Llama-2-13b-chat-hf",
            "iteration": "3",
            "item_id": "26",
            "error": "'choices'"
        },
        {
            "model": "Llama-2-13b-chat-hf",
            "iteration": "3",
            "item_id": "22",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "32",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "33",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "34",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "35",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "36",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "37",
            "error": "'choices'"
        },
        {
            "model": "gemma-2b-it",
            "iteration": "1",
            "item_id": "38",
            "error": "'choices'"
        }
    ],
    "end_time": "2025-02-02T15:16:29.769501",
    "raw_score_distribution": {
        "count": 2040,
        "min": 2.86,
        "max": 9.07,
        "mean": 6.254,
        "median": 6.18,
        "stdev": 1.075,
        "p10": 4.93,
        "p25": 5.52,
        "p75": 7.04,
        "p90": 7.75
    },
    "calibration_config": {
        "method": "piecewise_landmark",
        "in_landmarks": [
            2.86,
            5.52,
            6.18,
            7.04,
            9.07
        ],
        "out_landmarks": [
            0,
            3,
            5,
            7,
            10
        ]
    },
    "calibrated_score_distribution": {
        "count": 2040,
        "min": 0.0,
        "max": 10.0,
        "mean": 5.041,
        "median": 5.0,
        "stdev": 2.178,
        "p10": 2.335,
        "p25": 3.0,
        "p75": 7.0,
        "p90": 8.049
    },
    "raw_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.931333333333333,
            "median": 6.96,
            "stdev": 0.8119764592080999,
            "ci95": 0.1452810221380069,
            "min": 4.18,
            "max": 8.68,
            "length_correlation": 0.004887538230883041
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 5.886583333333333,
            "median": 5.75,
            "stdev": 0.6798794948010863,
            "ci95": 0.12164587632467196,
            "min": 4.14,
            "max": 7.93,
            "length_correlation": -0.0628606031402447
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.5921666666666665,
            "median": 6.5,
            "stdev": 0.7315325036671771,
            "ci95": 0.1308877722435362,
            "min": 4.32,
            "max": 8.39,
            "length_correlation": 0.15442533867832367
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.8613333333333335,
            "median": 6.98,
            "stdev": 0.7475123262335869,
            "ci95": 0.13374692527649013,
            "min": 5.18,
            "max": 8.39,
            "length_correlation": -0.00500281174717462
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 6.347583333333334,
            "median": 6.21,
            "stdev": 0.6545034628733184,
            "ci95": 0.11710552812311407,
            "min": 5.04,
            "max": 8.64,
            "length_correlation": -0.2597377528850057
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 5.960333333333334,
            "median": 6.0,
            "stdev": 0.8141283252485377,
            "ci95": 0.14566603982455875,
            "min": 3.39,
            "max": 7.96,
            "length_correlation": -0.10963852520822913
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 5.444083333333333,
            "median": 5.39,
            "stdev": 0.72492885287916,
            "ci95": 0.1297062292006982,
            "min": 3.45,
            "max": 7.75,
            "length_correlation": 0.20800243991775466
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 5.302,
            "median": 5.285,
            "stdev": 0.7715700461620149,
            "ci95": 0.13805139753289103,
            "min": 3.64,
            "max": 7.64,
            "length_correlation": -0.010840947389215042
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 4.9575,
            "median": 4.915,
            "stdev": 0.9278422152880241,
            "ci95": 0.16601203629881306,
            "min": 2.86,
            "max": 7.68,
            "length_correlation": 0.1538164385717465
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 5.965416666666667,
            "median": 6.0,
            "stdev": 0.789254403855691,
            "ci95": 0.14121553059667108,
            "min": 3.46,
            "max": 7.82,
            "length_correlation": 0.05666765394326993
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 5.952416666666667,
            "median": 6.0,
            "stdev": 0.7422484530845737,
            "ci95": 0.13280509886906042,
            "min": 3.89,
            "max": 8.11,
            "length_correlation": 0.11406013986958664
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 7.065083333333333,
            "median": 7.14,
            "stdev": 0.7454038393740009,
            "ci95": 0.13336966911019196,
            "min": 4.86,
            "max": 8.54,
            "length_correlation": 0.0089205903576836
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 6.652666666666667,
            "median": 6.66,
            "stdev": 0.8014301642209689,
            "ci95": 0.14339405054157214,
            "min": 3.64,
            "max": 8.18,
            "length_correlation": -0.00733407615953954
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.46025,
            "median": 7.5600000000000005,
            "stdev": 0.6878140535558339,
            "ci95": 0.12306554901718822,
            "min": 5.68,
            "max": 9.07,
            "length_correlation": 0.10773790649413349
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 7.7955,
            "median": 7.93,
            "stdev": 0.6658549189645171,
            "ci95": 0.11913656131992921,
            "min": 5.83,
            "max": 9.07,
            "length_correlation": -0.056366797760397915
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 5.51275,
            "median": 5.43,
            "stdev": 0.6678335253991512,
            "ci95": 0.11949057892964271,
            "min": 3.64,
            "max": 8.04,
            "length_correlation": -0.033054950608002835
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 5.62325,
            "median": 5.68,
            "stdev": 0.7241003255852085,
            "ci95": 0.1295579868584856,
            "min": 3.18,
            "max": 7.21,
            "length_correlation": -0.3417965899336407
        }
    },
    "calibrated_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.484058074915607,
            "median": 6.813953488372093,
            "stdev": 1.642210871907668,
            "ci95": 0.2938288066498585,
            "min": 1.488721804511278,
            "max": 9.423645320197043,
            "length_correlation": 0.020567585156436387
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 4.1846855815390835,
            "median": 3.696969696969698,
            "stdev": 1.5232369178421283,
            "ci95": 0.27254166530674717,
            "min": 1.443609022556391,
            "max": 8.31527093596059,
            "length_correlation": -0.056861049955069604
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 5.808875712738141,
            "median": 5.744186046511628,
            "stdev": 1.5636725120236084,
            "ci95": 0.27977651107945883,
            "min": 1.6466165413533842,
            "max": 8.995073891625616,
            "length_correlation": 0.13612498856047373
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.349539624193531,
            "median": 6.8604651162790695,
            "stdev": 1.596985571963999,
            "ci95": 0.28573697377982415,
            "min": 2.6165413533834587,
            "max": 8.995073891625616,
            "length_correlation": 0.02751582728304604
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.247250984956742,
            "median": 5.069767441860465,
            "stdev": 1.476214131394102,
            "ci95": 0.264128221294332,
            "min": 2.458646616541354,
            "max": 9.364532019704434,
            "length_correlation": -0.24488752674032654
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.401437823831042,
            "median": 4.454545454545455,
            "stdev": 1.7490026321958014,
            "ci95": 0.3129362769645869,
            "min": 0.597744360902256,
            "max": 8.35960591133005,
            "length_correlation": -0.08213703299998706
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 3.2960173863615814,
            "median": 2.8533834586466167,
            "stdev": 1.4125064181057465,
            "ci95": 0.252729465086998,
            "min": 0.6654135338345868,
            "max": 8.049261083743842,
            "length_correlation": 0.20581437760038646
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 3.1066210313577685,
            "median": 2.734962406015038,
            "stdev": 1.4181045657770885,
            "ci95": 0.2537311007952121,
            "min": 0.8796992481203012,
            "max": 7.886699507389162,
            "length_correlation": -0.0072533777032410445
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 2.638693977416385,
            "median": 2.317669172932331,
            "stdev": 1.5399107567996864,
            "ci95": 0.27552499362771976,
            "min": 0.0,
            "max": 7.945812807881772,
            "length_correlation": 0.15881792071104328
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.438626925780833,
            "median": 4.454545454545455,
            "stdev": 1.6876899752324503,
            "ci95": 0.3019660507066484,
            "min": 0.6766917293233085,
            "max": 8.152709359605911,
            "length_correlation": 0.05831939676378383
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 4.360527943452226,
            "median": 4.454545454545455,
            "stdev": 1.5832824028081893,
            "ci95": 0.28328516572688184,
            "min": 1.1616541353383463,
            "max": 8.581280788177338,
            "length_correlation": 0.1215983834505551
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 6.771913572295541,
            "median": 7.147783251231527,
            "stdev": 1.4853895417253336,
            "ci95": 0.2657699105038406,
            "min": 2.255639097744362,
            "max": 9.216748768472904,
            "length_correlation": 0.02575071922915363
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.958142165941938,
            "median": 6.116279069767441,
            "stdev": 1.6583860401319717,
            "ci95": 0.29672291145576984,
            "min": 0.8796992481203012,
            "max": 8.684729064039407,
            "length_correlation": 0.020667171114271674
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.506867882629711,
            "median": 7.768472906403941,
            "stdev": 1.2270889801447957,
            "ci95": 0.2195540760671624,
            "min": 3.4848484848484853,
            "max": 10.0,
            "length_correlation": 0.10741018698985152
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 8.049436049115279,
            "median": 8.31527093596059,
            "stdev": 1.150840191581977,
            "ci95": 0.2059114367842518,
            "min": 3.939393939393941,
            "max": 10.0,
            "length_correlation": -0.03731343515206532
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 3.3952087424948614,
            "median": 2.898496240601504,
            "stdev": 1.3373426986812507,
            "ci95": 0.2392809693063014,
            "min": 0.8796992481203012,
            "max": 8.47783251231527,
            "length_correlation": -0.03705574201012099
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 3.698784194545074,
            "median": 3.4848484848484853,
            "stdev": 1.4024476391178018,
            "ci95": 0.25092972117046364,
            "min": 0.3609022556390981,
            "max": 7.251231527093596,
            "length_correlation": -0.2693020691541622
        }
    },
    "raw_cross_model_stats": {
        "anova_f": 136.01826114874498,
        "anova_p": 3.319904405376065e-306,
        "kw_stat": 1068.3371431512385,
        "kw_p": 2.5737874081938e-217,
        "std_dev_across_models": 0.774017182067254,
        "pearson_r": 0.9772377063783787,
        "kendall_tau": 0.9117647058823528,
        "normalized_components": {
            "pearson_r": 0.924125687927929,
            "kendall_tau": 0.9019607843137254,
            "anova_f": 0.3886236032821285,
            "kw_stat": 0.5935206350840214,
            "std_dev": 0.29769891617971306,
            "ci99_overlap_magnitude_sum_norm": 0.764587290429488,
            "ci99_overlap_magnitude_pct_norm": 0.4939361314234746,
            "raw_score_range_norm": 0.2838,
            "kendall_tau_bootstrapped": 0.8062499999999999
        }
    },
    "calibrated_cross_model_stats": {
        "anova_f": 140.42688244717766,
        "anova_p": 1.77691700845e-313,
        "kw_stat": 1068.3371431512385,
        "kw_p": 2.5737874081938e-217,
        "std_dev_across_models": 1.579864307785328,
        "pearson_r": 0.9721482238908548,
        "kendall_tau": 0.9088235294117646,
        "normalized_components": {
            "pearson_r": 0.9071607463028492,
            "kendall_tau": 0.8986928104575163,
            "anova_f": 0.4012196641347933,
            "kw_stat": 0.5935206350840214,
            "std_dev": 0.6076401183789724,
            "ci99_overlap_magnitude_sum_norm": 0.5365180735782752,
            "ci99_overlap_magnitude_pct_norm": 0.4782443851249787,
            "calibrated_score_range_norm": 0.5410742071698894,
            "kendall_tau_bootstrapped": 0.8045833333333332
        }
    },
    "separability_metrics": {
        "raw": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": false,
                "gemini-1.5-pro-002__claude-3-5-sonnet-20240620": true,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": true,
                "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": false,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gemma-7b-it": true,
                "gemma-7b-it__gemma-2b-it": true
            },
            "adjacent_overlap_fraction": 0.8125,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.14220252029673297,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": 0.11034354964541926,
                "gemini-1.5-pro-002__claude-3-5-sonnet-20240620": 0.41555353263107264,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.48004721693318686,
                "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.33766076705244163,
                "Mistral-Large-Instruct-2411__claude-3-opus-20240229": 0.4801911912454244,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.24428534791785683,
                "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.12706110331358733,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.5567557681027218,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.523596834685156,
                "c4ai-command-r-08-2024__claude-3-haiku-20240307": 0.4357653489783573,
                "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.23186432377268584,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": 0.3804489237988937,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.4225744869555168,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.385746723699131,
                "gemma-7b-it__gemma-2b-it": 0.2548996196439326
            },
            "ci99_overlap_magnitude_sum": 5.528997258672117,
            "ci99_overlap_scale_factor": 1.5,
            "ci99_overlap_percentage_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.0,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": 0.0,
                "gemini-1.5-pro-002__claude-3-5-sonnet-20240620": 0.635926781628583,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.8104922040683677,
                "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.42760162614899117,
                "Mistral-Large-Instruct-2411__claude-3-opus-20240229": 0.8338929718107649,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.2503159672795925,
                "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.0,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.9847235867974178,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.9558547037765708,
                "c4ai-command-r-08-2024__claude-3-haiku-20240307": 0.8046771473597276,
                "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.20253964274219816,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": 0.6634726575124454,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.7916574195687327,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.5968039265656164,
                "gemma-7b-it__gemma-2b-it": 0.1390632619653988
            },
            "ci99_overlap_percentage_adjacent_avg": 0.5060638685765254,
            "average_cohens_d_adjacent": 0.24287621777446824,
            "cohens_d_norm": 0.6071905444361706,
            "emd": {
                "average": 0.9417365196078435,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 1.04475,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.3415,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.09083333333333338,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 0.5980833333333335,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 0.9710000000000001,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 1.48725,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 1.6293333333333333,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 1.9738333333333333,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 0.9659166666666668,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 0.9789166666666668,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.14791666666666672,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 0.2786666666666667,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.5289166666666667,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 0.8641666666666665,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 1.4185833333333333,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 1.3080833333333333,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 0.7055833333333333,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 0.97475,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.461,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.1434166666666667,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 0.4425,
                    "claude-3-haiku-20240307__gemma-7b-it": 0.5845833333333332,
                    "claude-3-haiku-20240307__gemma-2b-it": 0.9290833333333333,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.15066666666666667,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.10233333333333339,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 1.1785,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.7744166666666668,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 1.5736666666666668,
                    "claude-3-haiku-20240307__DeepSeek-R1": 1.9089166666666668,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 0.378,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.2633333333333333,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.27149999999999996,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.26508333333333334,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 0.6318333333333332,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 1.1480833333333336,
                    "claude-3-opus-20240229__gemma-7b-it": 1.2901666666666667,
                    "claude-3-opus-20240229__gemma-2b-it": 1.6346666666666665,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 0.6267499999999999,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 0.6397499999999998,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.47291666666666665,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.13566666666666666,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 0.8680833333333334,
                    "claude-3-opus-20240229__DeepSeek-R1": 1.2033333333333334,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 1.0794166666666667,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 0.9689166666666666,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 0.5179166666666667,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 0.901,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 1.4172500000000001,
                    "gemini-1.5-pro-001__gemma-7b-it": 1.5593333333333332,
                    "gemini-1.5-pro-001__gemma-2b-it": 1.9038333333333333,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 0.8959166666666667,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 0.9089166666666666,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.20908333333333334,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.2115,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.5989166666666667,
                    "gemini-1.5-pro-001__DeepSeek-R1": 0.9341666666666666,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 1.3485833333333335,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 1.2380833333333332,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.38841666666666663,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 0.9035,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 1.0455833333333333,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 1.3900833333333331,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.38216666666666665,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.3968333333333332,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 0.7221666666666666,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.36558333333333337,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 1.1126666666666667,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 1.4479166666666667,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 0.8348333333333334,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 0.7243333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.5172500000000001,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 0.6625000000000001,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.0028333333333335,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.05991666666666664,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.11975,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 1.10475,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.6923333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 1.4999166666666666,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 1.8351666666666668,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.45308333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.3370833333333333,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.15341666666666667,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.48891666666666667,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.5213333333333333,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.5083333333333334,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 1.621,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 1.2085833333333333,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 2.016166666666667,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 2.351416666666667,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.1073333333333333,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.23333333333333334,
                    "gemma-7b-it__gemma-2b-it": 0.3486666666666667,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 0.6664166666666667,
                    "gemma-7b-it__c4ai-command-r-08-2024": 0.6504166666666666,
                    "gemma-7b-it__gemini-1.5-pro-002": 1.7630833333333333,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 1.3506666666666667,
                    "gemma-7b-it__gpt-4o-2024-11-20": 2.15825,
                    "gemma-7b-it__DeepSeek-R1": 2.4935000000000005,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.22508333333333333,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.35824999999999996,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 1.0079166666666666,
                    "gemma-2b-it__c4ai-command-r-08-2024": 0.9949166666666668,
                    "gemma-2b-it__gemini-1.5-pro-002": 2.1075833333333334,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 1.6951666666666667,
                    "gemma-2b-it__gpt-4o-2024-11-20": 2.50275,
                    "gemma-2b-it__DeepSeek-R1": 2.838,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.5559166666666666,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.6812499999999999,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.10933333333333337,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 1.0996666666666666,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.6872499999999999,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 1.4948333333333332,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 1.8300833333333335,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.45933333333333337,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.3421666666666667,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 1.1126666666666667,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.7044166666666667,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 1.5078333333333331,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 1.8430833333333336,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.4413333333333334,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.3291666666666667,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 0.41241666666666665,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.39516666666666667,
                    "gemini-1.5-pro-002__DeepSeek-R1": 0.7304166666666667,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 1.5523333333333333,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 1.4418333333333333,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 0.8075833333333333,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 1.1428333333333334,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 1.1399166666666667,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 1.0294166666666666,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.33525000000000005,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 1.9475,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 1.8370000000000002,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 2.28275,
                    "DeepSeek-R1__databricks/dbrx-instruct": 2.1722500000000005,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.20283333333333337
                }
            },
            "average_ci95": 0.13353752071797187,
            "modulated_ci95": 0.8305806481716657
        },
        "calibrated": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": true,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": false,
                "gemini-1.5-pro-002__claude-3-5-sonnet-20240620": true,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": true,
                "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": false,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gemma-7b-it": true,
                "gemma-7b-it__gemma-2b-it": true
            },
            "adjacent_overlap_fraction": 0.875,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.29615112100331054,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": 0.22176386287355587,
                "gemini-1.5-pro-002__claude-3-5-sonnet-20240620": 0.8152802989513441,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 1.0079783762409065,
                "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.7568045115429785,
                "Mistral-Large-Instruct-2411__claude-3-opus-20240229": 0.9871856687696177,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.5105735487395187,
                "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.3073164110215192,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 1.1749665876695938,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 1.1168789252142997,
                "c4ai-command-r-08-2024__claude-3-haiku-20240307": 0.919857923093347,
                "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.5460166769274486,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": 0.662775870482688,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.8707077978683149,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.8089883133824287,
                "gemma-7b-it__gemma-2b-it": 0.5753943928160901
            },
            "ci99_overlap_magnitude_sum": 11.578640286596963,
            "ci99_overlap_scale_factor": 1.5,
            "ci99_overlap_percentage_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.029679336309614068,
                "gpt-4o-2024-11-20__gemini-1.5-pro-002": 0.0,
                "gemini-1.5-pro-002__claude-3-5-sonnet-20240620": 0.610119510535152,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.8235493901506403,
                "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.4888560378461003,
                "Mistral-Large-Instruct-2411__claude-3-opus-20240229": 0.8036780702063424,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.21446734936084833,
                "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.0,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.954283531371638,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.9501392136903442,
                "c4ai-command-r-08-2024__claude-3-haiku-20240307": 0.7595577781234293,
                "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.29419336448848415,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": 0.5290796775944627,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.8472283497791014,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.7154486165090276,
                "gemma-7b-it__gemma-2b-it": 0.3278096120351569
            },
            "ci99_overlap_percentage_adjacent_avg": 0.5217556148750213,
            "average_cohens_d_adjacent": 0.23282716456072522,
            "cohens_d_norm": 0.582067911401813,
            "emd": {
                "average": 1.923101529786956,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 2.2993724933765236,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.6778139411248347,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.16102728495682117,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 1.252972503492699,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 2.082620251084565,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 3.1880406885540253,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 3.3774370435578387,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 3.8453640974992216,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 2.0454311491347745,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 2.123530131463381,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.309610970178965,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 0.5259159089736686,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 1.0228098077141041,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 1.5653779741996725,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 3.0888493324207458,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 2.785273880370533,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 1.6241901311990574,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 2.1648540426544476,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 1.0625654034176593,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.3016652824681567,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 0.8886681951775017,
                    "claude-3-haiku-20240307__gemma-7b-it": 1.0780645501813149,
                    "claude-3-haiku-20240307__gemma-2b-it": 1.545991604122698,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.3370414010713888,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.22958427483498187,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 2.5872279907564586,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 1.7828550806434567,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 3.3221823010906277,
                    "claude-3-haiku-20240307__DeepSeek-R1": 3.8647504675761963,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 0.7956344745122022,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.48590138699400925,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.5441121873174588,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.5874717382019115,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 1.4074378889070986,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 2.51285832637656,
                    "claude-3-opus-20240229__gemma-7b-it": 2.7022546813803725,
                    "claude-3-opus-20240229__gemma-2b-it": 3.170181735321756,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 1.3702487869573081,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 1.448347769285915,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.963037859557401,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.25479981377345573,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 1.6979921698915703,
                    "claude-3-opus-20240229__DeepSeek-R1": 2.2405603363771385,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 2.413666970243279,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 2.110091518193067,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 1.1084462747047685,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 1.9481018003624886,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 3.0535222378319493,
                    "gemini-1.5-pro-001__gemma-7b-it": 3.2429185928357622,
                    "gemini-1.5-pro-001__gemma-2b-it": 3.710845646777145,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 1.9109126984126983,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 1.9890116807413047,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.42838898569599604,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.3955846503698189,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 1.1573282584361804,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.6998964249217487,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 2.9543308816986693,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 2.6507554296484566,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.847537299056735,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 1.9512335985951608,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 2.140629953598974,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 2.608557007540357,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.8086240591759098,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.889186095691709,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 1.530509100172608,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.7827589381524086,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 2.2596168976729682,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 2.802185064158537,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 1.852042242461881,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 1.5484667904116685,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 1.1065482570183327,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 1.2995160405935742,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.7627438464146565,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.1266037045908737,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.22961642992928605,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 2.3704757484645,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 1.5567043421108968,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 3.105430058798669,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 3.647998225284237,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 1.012898772806235,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.702653629285968,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.21689308308193636,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.6623258910928267,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 1.1426095394192513,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 1.0645105570906441,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 3.4758961859339603,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 2.662124779580357,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 4.2108504962681295,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 4.753418662753699,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.1891138367534348,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.49103248038323805,
                    "gemma-7b-it__gemma-2b-it": 0.47827228654002396,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 1.3353893530696805,
                    "gemma-7b-it__c4ai-command-r-08-2024": 1.253906912094457,
                    "gemma-7b-it__gemini-1.5-pro-002": 3.6652925409377732,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 2.8515211345841696,
                    "gemma-7b-it__gpt-4o-2024-11-20": 4.400246851271943,
                    "gemma-7b-it__DeepSeek-R1": 4.942815017757511,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.32239085889372887,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.6462254439895516,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 1.7999329483644475,
                    "gemma-2b-it__c4ai-command-r-08-2024": 1.7218339660358406,
                    "gemma-2b-it__gemini-1.5-pro-002": 4.133219594879156,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 3.319448188525553,
                    "gemma-2b-it__gpt-4o-2024-11-20": 4.868173905213325,
                    "gemma-2b-it__DeepSeek-R1": 5.410742071698894,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.7580651526753752,
                    "gemma-2b-it__databricks/dbrx-instruct": 1.0880831143677767,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.20729658448446697,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 2.3332866465147095,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 1.5195152401611058,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 3.0682409568488787,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 3.6108091233344464,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 1.0522203611444105,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.7398427312357585,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 2.4113856288433158,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 1.6023134706100137,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 3.1463399391774853,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 3.688908105663054,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.9671989002054846,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.6617437489071516,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 0.8137714063536032,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.7349543103341694,
                    "gemini-1.5-pro-002__DeepSeek-R1": 1.2775224768197375,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 3.3767048298006808,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 3.073129377750468,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 1.5487257166877726,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 2.091293883173341,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 2.5629334234470775,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 2.259357971396864,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.5425681664855683,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 4.11165914013485,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 3.808083688084637,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 4.6542273066204185,
                    "DeepSeek-R1__databricks/dbrx-instruct": 4.350651854570206,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.4245227179696223
                }
            },
            "average_ci95": 0.26790319154741515,
            "modulated_ci95": 0.4760494907871948
        }
    },
    "iteration_stability": {
        "raw": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.931333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.18310637466905513
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 5.886583333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.13023520389408275
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.5921666666666665,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.17850097260861697
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.8613333333333335,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.04297883846214984
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 6.347583333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.0675860562542306
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 5.960333333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08785855109208227
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 5.444083333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14530270128252956
                },
                "gemma-7b-it": {
                    "mean_iter_score": 5.302,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14390255190386456
                },
                "gemma-2b-it": {
                    "mean_iter_score": 4.9575,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07860414181906131
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 5.965416666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.18738681769122503
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 5.952416666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07375466086966984
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 7.065083333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09846544797259825
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 6.652666666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07426706687504366
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.46025,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.05657811708897137
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 7.7955,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07117339936927133
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 5.51275,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11611554350923242
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 5.6232500000000005,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14111520116557244
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8676470588235293,
                        "p_value": 9.575975226992579e-09
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8970588235294118,
                        "p_value": 1.2313901628307946e-09
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8676470588235293,
                        "p_value": 9.575975226992579e-09
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8823529411764705,
                        "p_value": 3.5743855407137387e-09
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8823529411764705,
                        "p_value": 3.5743855407137387e-09
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    }
                },
                "average_kendall_tau": 0.8999999999999999
            },
            "randomized_average_kendall_tau_by_item": 0.8837499999999999
        },
        "calibrated": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.484058074915607,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3530889668626175
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 4.1846855815390835,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.329255919696424
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 5.808875712738141,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3814588047017121
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.349539624193531,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11473478281724635
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.247250984956742,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1393975532170441
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 4.401437823831042,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2176439200841361
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 3.2960173863615814,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.26625618891167063
                },
                "gemma-7b-it": {
                    "mean_iter_score": 3.1066210313577685,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2476269313126782
                },
                "gemma-2b-it": {
                    "mean_iter_score": 2.6386939774163856,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1972710932138357
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.438626925780833,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.39468207341794065
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 4.360527943452226,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.18174125510964595
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 6.771913572295541,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2091935900680168
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.958142165941938,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.16891339990451704
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.506867882629711,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.12377901223717024
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 8.049436049115279,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11434728149474835
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 3.3952087424948614,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1839912960235732
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 3.6987841945450737,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3080640287542402
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8676470588235293,
                        "p_value": 9.575975226992579e-09
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8970588235294118,
                        "p_value": 1.2313901628307946e-09
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8823529411764705,
                        "p_value": 3.5743855407137387e-09
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8823529411764705,
                        "p_value": 3.5743855407137387e-09
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8823529411764705,
                        "p_value": 3.5743855407137387e-09
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.8970588235294118,
                        "p_value": 1.2313901628307946e-09
                    }
                },
                "average_kendall_tau": 0.8999999999999999
            },
            "randomized_average_kendall_tau_by_item": 0.8827499999999999
        }
    },
    "raw_score_range": 2.838,
    "final_judgemark_score_elements_raw": {
        "norm_stability_between_iterations": 0.8062499999999999,
        "norm_correlation_with_lmsys_arena": 0.9019607843137254,
        "norm_std_dev_between_models": 0.29769891617971306,
        "norm_kruskall_wallis": 0.5935206350840214,
        "norm_ci99_adjacent_overlap": 0.4939361314234746,
        "norm_score_range": 0.2838,
        "norm_intra_model_ci95": 0.8305806481716657,
        "norm_earth_movers_distance": 0.2354341299019609
    },
    "final_judgemark_score_raw": 0.5885874041368249,
    "calibrated_score_range": 5.410742071698894,
    "final_judgemark_score_elements_calibrated": {
        "norm_stability_between_iterations": 0.8045833333333332,
        "norm_correlation_with_lmsys_arena": 0.8986928104575163,
        "norm_std_dev_between_models": 0.6076401183789724,
        "norm_kruskall_wallis": 0.5935206350840214,
        "norm_ci99_adjacent_overlap": 0.4782443851249787,
        "norm_score_range": 0.5410742071698894,
        "norm_intra_model_ci95": 0.4760494907871948,
        "norm_earth_movers_distance": 0.480775382446739
    },
    "final_judgemark_score": 0.6369131594086744
}