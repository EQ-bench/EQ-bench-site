{
    "judge_model": "google/gemini-2.5-pro-preview-03-25",
    "start_time": "2025-04-05T12:04:59.318254",
    "status": "completed",
    "samples_file": "data/judgemark_v2.1_samples.json",
    "prompts_file": "data/judge_prompts.json",
    "scoring_range": {
        "min": 0,
        "max": 10
    },
    "end_time": "2025-04-05T14:12:33.216551",
    "raw_score_distribution": {
        "count": 2038,
        "min": 2.19,
        "max": 9.36,
        "mean": 5.535,
        "median": 5.29,
        "stdev": 1.496,
        "p10": 3.73,
        "p25": 4.31,
        "p75": 6.79,
        "p90": 7.75
    },
    "calibration_config": {
        "method": "piecewise_landmark",
        "in_landmarks": [
            2.19,
            4.31,
            5.29,
            6.79,
            9.36
        ],
        "out_landmarks": [
            0,
            3,
            5,
            7,
            10
        ]
    },
    "calibrated_score_distribution": {
        "count": 2038,
        "min": 0.0,
        "max": 10.0,
        "mean": 5.016,
        "median": 4.996,
        "stdev": 2.218,
        "p10": 2.179,
        "p25": 3.0,
        "p75": 7.0,
        "p90": 8.121
    },
    "raw_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 119,
            "mean": 7.1452100840336135,
            "median": 7.2,
            "stdev": 0.8272015809285369,
            "ci95": 0.14862571141140382,
            "min": 4.1,
            "max": 8.7,
            "length_correlation": -0.12929401345258454,
            "length_correlation_p": 0.16108449657618445
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 5.466333333333333,
            "median": 5.41,
            "stdev": 0.7806880539210358,
            "ci95": 0.13968281611907118,
            "min": 3.64,
            "max": 7.9,
            "length_correlation": 0.19357398842213513,
            "length_correlation_p": 0.03414277204649211
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.233416666666667,
            "median": 6.27,
            "stdev": 1.0419136368291972,
            "ci95": 0.1864220032754416,
            "min": 3.9,
            "max": 8.6,
            "length_correlation": 0.032352660034438534,
            "length_correlation_p": 0.7257474375911672
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.6545,
            "median": 6.71,
            "stdev": 0.765438140033855,
            "ci95": 0.13695426031930458,
            "min": 4.79,
            "max": 9.03,
            "length_correlation": -0.008651686815218804,
            "length_correlation_p": 0.9252805582415038
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.534583333333333,
            "median": 5.484999999999999,
            "stdev": 0.6662435719756549,
            "ci95": 0.1192061001668684,
            "min": 4.0,
            "max": 7.17,
            "length_correlation": -0.09966524587990556,
            "length_correlation_p": 0.2787863705072563
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.774583333333333,
            "median": 4.720000000000001,
            "stdev": 0.7379108550305985,
            "ci95": 0.13202900410453988,
            "min": 2.76,
            "max": 6.88,
            "length_correlation": -0.19077028021151193,
            "length_correlation_p": 0.036877434467907366
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 4.343583333333333,
            "median": 4.3,
            "stdev": 0.5560270168052691,
            "ci95": 0.09948585629760633,
            "min": 3.02,
            "max": 5.53,
            "length_correlation": 0.2440116889690345,
            "length_correlation_p": 0.007236494820922479
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 3.90975,
            "median": 3.83,
            "stdev": 0.4740677937903436,
            "ci95": 0.08482149065225504,
            "min": 2.91,
            "max": 5.53,
            "length_correlation": -0.039304082774250994,
            "length_correlation_p": 0.6699527701822087
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 3.6441666666666666,
            "median": 3.615,
            "stdev": 0.5492310642204808,
            "ci95": 0.09826990609766778,
            "min": 2.19,
            "max": 5.02,
            "length_correlation": 0.1852875396351029,
            "length_correlation_p": 0.04275890430477085
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.925083333333333,
            "median": 4.915,
            "stdev": 0.7285775202963872,
            "ci95": 0.1303590586341197,
            "min": 3.39,
            "max": 7.14,
            "length_correlation": 0.11241513158411232,
            "length_correlation_p": 0.22154293839529884
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 4.800833333333333,
            "median": 4.745,
            "stdev": 0.7102249416819398,
            "ci95": 0.12707536567758324,
            "min": 3.23,
            "max": 6.77,
            "length_correlation": 0.36837278558379827,
            "length_correlation_p": 3.478746263277851e-05
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 6.975,
            "median": 7.09,
            "stdev": 0.6534703737827482,
            "ci95": 0.11692068503150026,
            "min": 5.47,
            "max": 8.3,
            "length_correlation": 0.013982184047340236,
            "length_correlation_p": 0.8795250212047466
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.33325,
            "median": 5.305,
            "stdev": 1.0707855927842351,
            "ci95": 0.1915878516503591,
            "min": 3.09,
            "max": 7.56,
            "length_correlation": -0.04916362803982183,
            "length_correlation_p": 0.5938632199927975
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.593916666666667,
            "median": 7.5649999999999995,
            "stdev": 0.617536847243208,
            "ci95": 0.11049136136640415,
            "min": 5.73,
            "max": 9.17,
            "length_correlation": 0.04602008860902905,
            "length_correlation_p": 0.6176999603603598
        },
        "DeepSeek-R1": {
            "count": 119,
            "mean": 8.058991596638656,
            "median": 8.17,
            "stdev": 0.7853967959238369,
            "ci95": 0.14111452422925422,
            "min": 4.77,
            "max": 9.36,
            "length_correlation": 0.16836592393527183,
            "length_correlation_p": 0.06719637311624078
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 4.295333333333334,
            "median": 4.31,
            "stdev": 0.5390092581692423,
            "ci95": 0.09644099293845045,
            "min": 2.9,
            "max": 5.6,
            "length_correlation": 0.054833643598966426,
            "length_correlation_p": 0.5519550672087143
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 4.438833333333333,
            "median": 4.37,
            "stdev": 0.7325541633496436,
            "ci95": 0.1310705703545685,
            "min": 2.54,
            "max": 6.46,
            "length_correlation": -0.028896308746311602,
            "length_correlation_p": 0.7540562422584034
        }
    },
    "calibrated_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 119,
            "mean": 7.375673938657868,
            "median": 7.478599221789883,
            "stdev": 1.0506937813280994,
            "ci95": 0.18878120439534996,
            "min": 2.702830188679245,
            "max": 9.229571984435797,
            "length_correlation": -0.13599941289815823,
            "length_correlation_p": 0.1402716844131634
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 5.094327602678004,
            "median": 5.16,
            "stdev": 1.2176567713828315,
            "ci95": 0.21786643978852735,
            "min": 2.051886792452831,
            "max": 8.295719844357977,
            "length_correlation": 0.17991003580883325,
            "length_correlation_p": 0.04926833126899733
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.158742505028833,
            "median": 6.306666666666666,
            "stdev": 1.455276407225792,
            "ci95": 0.26038198710992916,
            "min": 2.419811320754717,
            "max": 9.11284046692607,
            "length_correlation": 0.02245090419214247,
            "length_correlation_p": 0.8077003460078436
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.772346241739238,
            "median": 6.893333333333333,
            "stdev": 0.9838338075870448,
            "ci95": 0.17603020328886307,
            "min": 3.979591836734694,
            "max": 9.614785992217898,
            "length_correlation": -0.01049597937154486,
            "length_correlation_p": 0.9094142891836746
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.2158025557774685,
            "median": 5.26,
            "stdev": 1.040848196188109,
            "ci95": 0.18623137175699142,
            "min": 2.5613207547169816,
            "max": 7.443579766536965,
            "length_correlation": -0.07210428762030732,
            "length_correlation_p": 0.4338533071189716
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 3.9307691564279583,
            "median": 3.8367346938775517,
            "stdev": 1.2495462040568865,
            "ci95": 0.22357218325159062,
            "min": 0.8066037735849054,
            "max": 7.1050583657587545,
            "length_correlation": -0.17721097044042064,
            "length_correlation_p": 0.052832930876717386
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 3.1886793736362473,
            "median": 2.9858490566037736,
            "stdev": 0.9664527525600495,
            "ci95": 0.17292033795776526,
            "min": 1.1745283018867927,
            "max": 5.32,
            "length_correlation": 0.25868468623365315,
            "length_correlation_p": 0.0043333876787830326
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 2.4746904761904767,
            "median": 2.3207547169811327,
            "stdev": 0.7578066049251009,
            "ci95": 0.1355888054363352,
            "min": 1.0188679245283023,
            "max": 5.32,
            "length_correlation": -0.03654858992898089,
            "length_correlation_p": 0.691875199415031
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 2.0767632524708,
            "median": 2.0165094339622645,
            "stdev": 0.816699286970249,
            "ci95": 0.14612604324285017,
            "min": 0.0,
            "max": 4.448979591836734,
            "length_correlation": 0.1819738888930376,
            "length_correlation_p": 0.04667908373545855
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.196997736047163,
            "median": 4.23469387755102,
            "stdev": 1.2428644682372167,
            "ci95": 0.2223766690238943,
            "min": 1.6981132075471703,
            "max": 7.408560311284046,
            "length_correlation": 0.12062664610691128,
            "length_correlation_p": 0.1893968719374586
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 3.985647156975998,
            "median": 3.887755102040817,
            "stdev": 1.2210820865357663,
            "ci95": 0.2184793064312974,
            "min": 1.4716981132075475,
            "max": 6.973333333333333,
            "length_correlation": 0.3506084794146813,
            "length_correlation_p": 8.64076058581335e-05
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 7.184133160397752,
            "median": 7.350194552529183,
            "stdev": 0.8132321389402656,
            "ci95": 0.14550569174868122,
            "min": 5.239999999999999,
            "max": 8.762645914396888,
            "length_correlation": 0.00982925911139168,
            "length_correlation_p": 0.9151462347580706
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 4.801838381435828,
            "median": 5.02,
            "stdev": 1.6936867287968203,
            "ci95": 0.30303900605832335,
            "min": 1.2735849056603774,
            "max": 7.898832684824902,
            "length_correlation": -0.03716713386771004,
            "length_correlation_p": 0.6869310890469216
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.933872460008647,
            "median": 7.904669260700389,
            "stdev": 0.7334612362503922,
            "ci95": 0.13123286628898878,
            "min": 5.586666666666667,
            "max": 9.778210116731518,
            "length_correlation": 0.043670066419761934,
            "length_correlation_p": 0.6357848428224812
        },
        "DeepSeek-R1": {
            "count": 119,
            "mean": 8.469613793266056,
            "median": 8.61089494163424,
            "stdev": 0.9597575670738785,
            "ci95": 0.17244243057262312,
            "min": 3.9387755102040813,
            "max": 10.0,
            "length_correlation": 0.17309759703165256,
            "length_correlation_p": 0.05975763192042396
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 3.1078075129422844,
            "median": 3.0,
            "stdev": 0.9148973765205349,
            "ci95": 0.16369591076804746,
            "min": 1.0047169811320755,
            "max": 5.413333333333333,
            "length_correlation": 0.06641083539170846,
            "length_correlation_p": 0.47110902613576255
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 3.357611506866898,
            "median": 3.1224489795918378,
            "stdev": 1.2447692151293075,
            "ci95": 0.22271747148467871,
            "min": 0.49528301886792475,
            "max": 6.56,
            "length_correlation": -0.004804310987995581,
            "length_correlation_p": 0.9584665214404144
        }
    },
    "length_correlation": {
        "raw": {
            "pearson_corr": 0.05138061108821317,
            "pearson_p": 0.38633769698456516
        },
        "calibrated": {
            "pearson_corr": 0.05487833608756801,
            "pearson_p": 0.41487689325682536
        }
    },
    "raw_cross_model_stats": {
        "anova_f": 398.9101227176765,
        "anova_p": 0.0,
        "kw_stat": 1514.4674705465081,
        "kw_p": 0.0,
        "std_dev_across_models": 1.3044318127555175,
        "pearson_r": 0.9555621729894865,
        "kendall_tau": 0.8823529411764706,
        "normalized_components": {
            "pearson_r": 0.8518739099649552,
            "kendall_tau": 0.869281045751634,
            "anova_f": 1.0,
            "kw_stat": 0.8413708169702823,
            "std_dev": 0.5017045433675067,
            "ci99_overlap_magnitude_sum_norm": 0.8506285241706284,
            "ci99_overlap_magnitude_pct_norm": 0.6738645680271529,
            "raw_score_range_norm": 0.4414824929971989,
            "kendall_tau_bootstrapped": 0.8990098039215685
        }
    },
    "calibrated_cross_model_stats": {
        "anova_f": 382.8843040404194,
        "anova_p": 0.0,
        "kw_stat": 1514.4674705465081,
        "kw_p": 0.0,
        "std_dev_across_models": 1.924007663171013,
        "pearson_r": 0.9558227631659979,
        "kendall_tau": 0.8735294117647058,
        "normalized_components": {
            "pearson_r": 0.8527425438866597,
            "kendall_tau": 0.8594771241830064,
            "anova_f": 1.0,
            "kw_stat": 0.8413708169702823,
            "std_dev": 0.7400029473734665,
            "ci99_overlap_magnitude_sum_norm": 0.7671135427779462,
            "ci99_overlap_magnitude_pct_norm": 0.677603430627929,
            "calibrated_score_range_norm": 0.6392850540795256,
            "kendall_tau_bootstrapped": 0.9035294117647058
        }
    },
    "separability_metrics": {
        "raw": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": false,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": false,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__gemma-7b-it": false,
                "gemma-7b-it__gemma-2b-it": false
            },
            "adjacent_overlap_fraction": 0.6875,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.030915233086177274,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.06209036821711855,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.35326097928994127,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.17996315587102973,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.21638762776832632,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.0,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.44209718642857787,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.5199498504269044,
                "Mistral-Large-Instruct-2411__Mixtral-8x22B-Instruct-v0.1": 0.22648661320409147,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.38322994940127053,
                "c4ai-command-r-08-2024__Mixtral-8x7B-Instruct-v0.1": 0.4845219094609927,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.18289764819618703,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.35924540808076166,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.33798019358233056,
                "gpt-3.5-turbo-0125__gemma-7b-it": 0.0,
                "gemma-7b-it__gemma-2b-it": 0.09534435925045415
            },
            "ci99_overlap_magnitude_sum": 3.8743704822641636,
            "ci99_overlap_scale_factor": 1.5,
            "ci99_overlap_percentage_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.0,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.0,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.5196731434667466,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.03963664092372525,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.009390291717279961,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.0,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.8044337673997666,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.7117854882733217,
                "Mistral-Large-Instruct-2411__Mixtral-8x22B-Instruct-v0.1": 0.03662472935402063,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.6328470761711169,
                "c4ai-command-r-08-2024__Mixtral-8x7B-Instruct-v0.1": 0.9232482522219327,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.02896542114397361,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.698754043741523,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.8128080571521457,
                "gpt-3.5-turbo-0125__gemma-7b-it": 0.0,
                "gemma-7b-it__gemma-2b-it": 0.0
            },
            "ci99_overlap_percentage_adjacent_avg": 0.32613543197284706,
            "average_cohens_d_adjacent": 0.3810652656929528,
            "cohens_d_norm": 0.952663164232382,
            "emd": {
                "average": 1.574074270884825,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 1.6788767507002804,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.9117934173669469,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.508344537815126,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 1.6106309523809523,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 2.3706267507002803,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 2.8016267507002803,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 3.235460084033613,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 3.5010434173669465,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 2.22012675070028,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 2.34437675070028,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.21238095238095234,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 1.8119600840336134,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.4487065826330533,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 0.9137815126050419,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 2.8498767507002807,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 2.7063767507002803,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 0.7670833333333332,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 1.188166666666667,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.12491666666666666,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.6917500000000001,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 1.12275,
                    "claude-3-haiku-20240307__gemma-7b-it": 1.5565833333333332,
                    "claude-3-haiku-20240307__gemma-2b-it": 1.8221666666666663,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.54125,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.6655,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 1.5086666666666668,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.32558333333333334,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 2.1275833333333334,
                    "claude-3-haiku-20240307__DeepSeek-R1": 2.592658263305322,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 1.1709999999999998,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 1.0274999999999999,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.4594166666666667,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.7014999999999999,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 1.4588333333333332,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 1.8898333333333335,
                    "claude-3-opus-20240229__gemma-7b-it": 2.323666666666667,
                    "claude-3-opus-20240229__gemma-2b-it": 2.58925,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 1.3083333333333331,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 1.4325833333333333,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.76475,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.9001666666666667,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 1.3605,
                    "claude-3-opus-20240229__DeepSeek-R1": 1.8255749299719888,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 1.9380833333333336,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 1.7945833333333336,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 1.1199166666666667,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 1.8799166666666671,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 2.310916666666667,
                    "gemini-1.5-pro-001__gemma-7b-it": 2.7447500000000007,
                    "gemini-1.5-pro-001__gemma-2b-it": 3.010333333333333,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 1.7294166666666668,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 1.8536666666666668,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.3373333333333334,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 1.32125,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.9394166666666667,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.4048557422969186,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 2.359166666666667,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 2.2156666666666673,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.76,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 1.1909999999999998,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 1.6248333333333331,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 1.8904166666666664,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.6094999999999999,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.73375,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 1.440416666666667,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.37516666666666676,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 2.0593333333333335,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 2.5244082633053218,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 1.2392499999999997,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 1.0957499999999998,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.4353333333333333,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 0.8673333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.1304166666666666,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.16133333333333338,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.06541666666666668,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 2.2004166666666665,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.5658333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 2.8193333333333337,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 3.2844082633053224,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.48158333333333325,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.33575,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.43383333333333335,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.6994166666666667,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.5814999999999999,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.45725000000000016,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 2.6314166666666665,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 0.9896666666666668,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 3.2503333333333324,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 3.715408263305322,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.07541666666666666,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.14375000000000002,
                    "gemma-7b-it__gemma-2b-it": 0.26558333333333334,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 1.0153333333333332,
                    "gemma-7b-it__c4ai-command-r-08-2024": 0.8910833333333336,
                    "gemma-7b-it__gemini-1.5-pro-002": 3.06525,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 1.4234999999999998,
                    "gemma-7b-it__gpt-4o-2024-11-20": 3.684166666666666,
                    "gemma-7b-it__DeepSeek-R1": 4.149241596638655,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.38625000000000004,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.5430833333333334,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 1.2809166666666667,
                    "gemma-2b-it__c4ai-command-r-08-2024": 1.1566666666666667,
                    "gemma-2b-it__gemini-1.5-pro-002": 3.330833333333333,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 1.689083333333333,
                    "gemma-2b-it__gpt-4o-2024-11-20": 3.9497499999999994,
                    "gemma-2b-it__DeepSeek-R1": 4.414824929971989,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.6511666666666667,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.7946666666666666,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.12741666666666662,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 2.0499166666666664,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.44233333333333336,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 2.668833333333333,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 3.133908263305322,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.6297499999999999,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.48624999999999996,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 2.1741666666666664,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.5395833333333333,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 2.7930833333333336,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 3.2581582633053223,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.5055,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.36383333333333334,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 1.64175,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.6189166666666666,
                    "gemini-1.5-pro-002__DeepSeek-R1": 1.0979649859943974,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 2.6796666666666664,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 2.5361666666666665,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 2.2606666666666664,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 2.7257415966386556,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 1.0379166666666668,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 0.8944166666666667,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.5139754901960785,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 3.2985833333333323,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 3.1550833333333337,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 3.763658263305322,
                    "DeepSeek-R1__databricks/dbrx-instruct": 3.620158263305322,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.16349999999999995
                }
            },
            "average_ci95": 0.12885632696037636,
            "modulated_ci95": 0.8675915228562859
        },
        "calibrated": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": false,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__claude-3-opus-20240229": false,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": false,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__gemma-7b-it": false,
                "gemma-7b-it__gemma-2b-it": false
            },
            "adjacent_overlap_fraction": 0.625,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.06289315277834184,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.07264455580484874,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.46743829027065154,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.2220561277041373,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.24669471363794138,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.0,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.6751222288997152,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.7343706092097557,
                "Mistral-Large-Instruct-2411__Mixtral-8x22B-Instruct-v0.1": 0.4309101906475892,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.6577078955886191,
                "c4ai-command-r-08-2024__Mixtral-8x7B-Instruct-v0.1": 0.8165371888417261,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.3066122258525139,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.610987864080887,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.5826990557743952,
                "gpt-3.5-turbo-0125__gemma-7b-it": 0.0,
                "gemma-7b-it__gemma-2b-it": 0.15741667613187182
            },
            "ci99_overlap_magnitude_sum": 6.044090775222994,
            "ci99_overlap_scale_factor": 1.5,
            "ci99_overlap_percentage_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.0,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.0,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.573618850580863,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.025731380921289196,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.0,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.0,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.7760174550648402,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.5884751766736513,
                "Mistral-Large-Instruct-2411__Mixtral-8x22B-Instruct-v0.1": 0.12704918863937156,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.6352573144109926,
                "c4ai-command-r-08-2024__Mixtral-8x7B-Instruct-v0.1": 0.9056566282814924,
                "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.02277126679446482,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.685964312800506,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.8178035357856639,
                "gpt-3.5-turbo-0125__gemma-7b-it": 0.0,
                "gemma-7b-it__gemma-2b-it": 0.0
            },
            "ci99_overlap_percentage_adjacent_avg": 0.32239656937207095,
            "average_cohens_d_adjacent": 0.3783448687783914,
            "cohens_d_norm": 0.9458621719459784,
            "emd": {
                "average": 2.3415027018691923,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 2.2813463359798627,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 1.2169314336290347,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.631870610827667,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 2.159877328654935,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 3.4449047822299095,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 4.18699456502162,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 4.900983462467391,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 5.298910686187067,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 3.178676202610704,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 3.390026781681869,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.2620879261399324,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 2.573835557222039,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.5581985213507794,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 1.0939398546081884,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 4.267866425715583,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 4.01806243179097,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 1.0644149023508285,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 1.6780186390612335,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.19020332953434416,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 1.1635584462500461,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 1.9056482290417571,
                    "claude-3-haiku-20240307__gemma-7b-it": 2.619637126487528,
                    "claude-3-haiku-20240307__gemma-2b-it": 3.017564350207204,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.8973298666308409,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 1.108680445702006,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 2.089805557719748,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.5456141671998069,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 2.839544857330642,
                    "claude-3-haiku-20240307__DeepSeek-R1": 3.375286190588051,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 1.9865200897357203,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 1.7367160958111065,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.6583508184224673,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.9467135341570247,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 2.227973348600875,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 2.9700631313925854,
                    "claude-3-opus-20240229__gemma-7b-it": 3.684052028838356,
                    "claude-3-opus-20240229__gemma-2b-it": 4.081979252558034,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 1.9617447689816696,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 2.1730953480528346,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 1.052433456925339,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 1.3569041235930048,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 1.775129954979814,
                    "claude-3-opus-20240229__DeepSeek-R1": 2.310871288237223,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 3.0509349920865487,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 2.801130998161935,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 1.5565436859617694,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 2.84157708531128,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 3.5836668681029904,
                    "gemini-1.5-pro-001__gemma-7b-it": 4.297655765548761,
                    "gemini-1.5-pro-001__gemma-2b-it": 4.695582989268438,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 2.5753485056920744,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 2.7866990847632396,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.43143672410598477,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 1.9705078603034096,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 1.161526218269409,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.698010705931437,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 3.6645387287969533,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 3.41473473487234,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 1.2850333993495102,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 2.027123182141221,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 2.7411120795869923,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 3.139039303306668,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 1.0188048197303048,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 1.2301553988014702,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 1.9683306046202835,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.6363065867930021,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 2.7180699042311782,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 3.2538112374885877,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 2.107995042835184,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 1.8581910489105704,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.748221858263409,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 1.4596164160865381,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.8540059039571581,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.28078203873870233,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.10904706255896386,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 3.2533640039697937,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.8812107344418322,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 4.003103303580689,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 4.538844636838098,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.8262635302781267,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.5731576495610602,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.7139888974457708,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 1.1119161211654474,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 1.0083183624109164,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.7969677833397509,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 3.9954537867615048,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 1.613159007799581,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 4.7451930863723994,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 5.2809344196298085,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.12998395584648947,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.23756420870234884,
                    "gemma-7b-it__gemma-2b-it": 0.3979272237196766,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 1.7223072598566869,
                    "gemma-7b-it__c4ai-command-r-08-2024": 1.510956680785522,
                    "gemma-7b-it__gemini-1.5-pro-002": 4.709442684207275,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 2.3271479052453516,
                    "gemma-7b-it__gpt-4o-2024-11-20": 5.459181983818169,
                    "gemma-7b-it__DeepSeek-R1": 5.99492331707558,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.6340604329782228,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.9027323514311385,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 2.120234483576364,
                    "gemma-2b-it__c4ai-command-r-08-2024": 1.9088839045051986,
                    "gemma-2b-it__gemini-1.5-pro-002": 5.107369907926952,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 2.7250751289650283,
                    "gemma-2b-it__gpt-4o-2024-11-20": 5.857109207537846,
                    "gemma-2b-it__DeepSeek-R1": 6.392850540795256,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 1.0310442604714845,
                    "gemma-2b-it__databricks/dbrx-instruct": 1.2808482543960982,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.21557280129338754,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 2.987135424350588,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.6533982759880742,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 3.736874723961483,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 4.272616057218892,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 1.0891902231048793,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.8393862291802655,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 3.1984860034217535,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.8263327338937921,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 3.9482253030326486,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 4.483966636290058,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.877839644033714,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.6304800945535447,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 2.3822947789619233,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.749739299610895,
                    "gemini-1.5-pro-002__DeepSeek-R1": 1.3102948633223905,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 4.076325647455468,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 3.826521653530854,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 3.132034078572819,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 3.6677754118302275,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 1.694030868493544,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 1.4442268745689302,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.6071190793901405,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 4.826064947066362,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 4.576260953141748,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 5.361806280323773,
                    "DeepSeek-R1__databricks/dbrx-instruct": 5.112002286399158,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.27894017669961046
                }
            },
            "average_ci95": 0.19335223109439625,
            "modulated_ci95": 0.6932617630406874
        }
    },
    "iteration_stability": {
        "raw": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 7.1443115942028985,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.13312575356534073
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 5.466333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.198210466143665
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.233416666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.20631916348759813
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.6545,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14391968246212894
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.534583333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08530378720262702
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 4.774583333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07553374889559113
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 4.343583333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09873772778876813
                },
                "gemma-7b-it": {
                    "mean_iter_score": 3.90975,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.056117807631208515
                },
                "gemma-2b-it": {
                    "mean_iter_score": 3.644166666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.03984431508313889
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.925083333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.0587901163273026
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 4.800833333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.0916337061954341
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 6.975,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09311246187034022
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.33325,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08256117260687523
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.593916666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.056271045445731444
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 8.058934782608695,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07880842351612709
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 4.295333333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08694682282866921
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 4.438833333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.13644326252654934
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9852941176470588,
                        "p_value": 9.55895466477477e-14
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    }
                },
                "average_kendall_tau": 0.9441176470588235
            },
            "randomized_average_kendall_tau_by_item": 0.9394058823529411
        },
        "calibrated": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 7.374244138016584,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.17452033665153044
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 5.094327602678004,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.30821263844492014
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.158742505028833,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.282045709765569
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.772346241739238,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1842110465918479
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.2158025557774685,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.13203691047931454
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 3.9307691564279583,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.12721663312999085
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 3.1886793736362473,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1685919498467918
                },
                "gemma-7b-it": {
                    "mean_iter_score": 2.4746904761904767,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08616905165361456
                },
                "gemma-2b-it": {
                    "mean_iter_score": 2.0767632524708004,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.05949227662618496
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.196997736047163,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09298809047224683
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 3.985647156975998,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1472739556935959
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 7.184133160397752,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11650092225090146
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 4.801838381435829,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.12304812200235726
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.933872460008647,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.0649897252836777
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 8.469595643772651,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09598878220270415
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 3.1078075129422844,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1414647950421291
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 3.357611506866898,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.23753822009105238
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9558823529411764,
                        "p_value": 5.347391697765181e-12
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.926470588235294,
                        "p_value": 1.080161877119549e-10
                    }
                },
                "average_kendall_tau": 0.9470588235294117
            },
            "randomized_average_kendall_tau_by_item": 0.9421176470588235
        }
    },
    "raw_score_range": 4.414824929971989,
    "final_judgemark_score_elements_raw": {
        "norm_stability_between_iterations": 0.8990098039215685,
        "norm_correlation_with_lmsys_arena": 0.869281045751634,
        "norm_std_dev_between_models": 0.5017045433675067,
        "norm_kruskall_wallis": 0.8413708169702823,
        "norm_ci99_adjacent_overlap": 0.6738645680271529,
        "norm_score_range": 0.4414824929971989,
        "norm_intra_model_ci95": 0.8675915228562859,
        "norm_earth_movers_distance": 0.39351856772120625
    },
    "final_judgemark_score_raw": 0.7997936032780121,
    "calibrated_score_range": 6.392850540795257,
    "final_judgemark_score_elements_calibrated": {
        "norm_stability_between_iterations": 0.9035294117647058,
        "norm_correlation_with_lmsys_arena": 0.8594771241830064,
        "norm_std_dev_between_models": 0.7400029473734665,
        "norm_kruskall_wallis": 0.8413708169702823,
        "norm_ci99_adjacent_overlap": 0.677603430627929,
        "norm_score_range": 0.6392850540795256,
        "norm_intra_model_ci95": 0.6932617630406874,
        "norm_earth_movers_distance": 0.5853756754672981
    },
    "final_judgemark_score": 0.8001591718573557
}