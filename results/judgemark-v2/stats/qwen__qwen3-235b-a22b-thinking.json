{
    "judge_model": "qwen/qwen3-235b-a22b",
    "start_time": "2025-04-29T17:55:33.211133",
    "status": "completed",
    "samples_file": "data/judgemark_v2.1_samples.json",
    "prompts_file": "data/judge_prompts.json",
    "scoring_range": {
        "min": 0,
        "max": 10
    },
    "end_time": "2025-04-29T19:53:19.478675",
    "raw_score_distribution": {
        "count": 2040,
        "min": 2.5,
        "max": 9.65,
        "mean": 5.878,
        "median": 5.79,
        "stdev": 1.118,
        "p10": 4.54,
        "p25": 5.23,
        "p75": 6.47,
        "p90": 7.273
    },
    "calibration_config": {
        "method": "piecewise_landmark",
        "in_landmarks": [
            2.5,
            5.23,
            5.79,
            6.47,
            9.65
        ],
        "out_landmarks": [
            0,
            3,
            5,
            7,
            10
        ]
    },
    "calibrated_score_distribution": {
        "count": 2040,
        "min": 0.0,
        "max": 10.0,
        "mean": 5.012,
        "median": 5.0,
        "stdev": 2.169,
        "p10": 2.242,
        "p25": 3.0,
        "p75": 7.0,
        "p90": 7.758
    },
    "raw_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.748833333333334,
            "median": 6.57,
            "stdev": 0.7934947520737786,
            "ci95": 0.14197422515777405,
            "min": 5.34,
            "max": 8.94,
            "length_correlation": -0.08316453452763048,
            "length_correlation_p": 0.36649836248540996
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 5.715,
            "median": 5.69,
            "stdev": 0.649608802771834,
            "ci95": 0.1162297623118056,
            "min": 3.31,
            "max": 7.78,
            "length_correlation": -0.07875664925173745,
            "length_correlation_p": 0.3925318774509609
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.2988333333333335,
            "median": 6.21,
            "stdev": 0.7982166923556423,
            "ci95": 0.14281908747224661,
            "min": 4.63,
            "max": 8.55,
            "length_correlation": -0.033093074878382714,
            "length_correlation_p": 0.7197294886325386
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.526666666666666,
            "median": 6.43,
            "stdev": 0.6962810373068947,
            "ci95": 0.12458048462872025,
            "min": 5.02,
            "max": 8.71,
            "length_correlation": -0.23630931784656206,
            "length_correlation_p": 0.00936444201483404
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.93675,
            "median": 5.8,
            "stdev": 0.6463396127098997,
            "ci95": 0.11564482999218584,
            "min": 4.73,
            "max": 7.93,
            "length_correlation": -0.13291065373340832,
            "length_correlation_p": 0.14785420313719658
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 5.508416666666666,
            "median": 5.63,
            "stdev": 0.6940806092644158,
            "ci95": 0.1241867780975429,
            "min": 2.56,
            "max": 7.59,
            "length_correlation": -0.12607849120441805,
            "length_correlation_p": 0.17001777937519963
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 5.091666666666667,
            "median": 5.205,
            "stdev": 0.6582027137021922,
            "ci95": 0.11776740807722975,
            "min": 2.5,
            "max": 6.43,
            "length_correlation": 0.16518172670305237,
            "length_correlation_p": 0.07139735801017899
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 4.771083333333333,
            "median": 4.855,
            "stdev": 0.6891021997764154,
            "ci95": 0.12329602761969823,
            "min": 2.67,
            "max": 6.26,
            "length_correlation": -0.21394369813643452,
            "length_correlation_p": 0.01895876291791116
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 4.379333333333333,
            "median": 4.4350000000000005,
            "stdev": 0.7732662725680699,
            "ci95": 0.1383548909448669,
            "min": 2.83,
            "max": 5.89,
            "length_correlation": 0.19982522641178985,
            "length_correlation_p": 0.02865628369055951
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 5.628333333333333,
            "median": 5.6,
            "stdev": 0.7209789485537723,
            "ci95": 0.12899950164569085,
            "min": 3.19,
            "max": 8.26,
            "length_correlation": -0.013771388754689256,
            "length_correlation_p": 0.8813279176000858
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 5.481583333333333,
            "median": 5.47,
            "stdev": 0.5396653115213018,
            "ci95": 0.09655837577693474,
            "min": 3.8,
            "max": 6.93,
            "length_correlation": 0.08703347120872541,
            "length_correlation_p": 0.34454665836531134
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 6.683333333333334,
            "median": 6.515000000000001,
            "stdev": 0.7949233178316591,
            "ci95": 0.1422298280033278,
            "min": 5.23,
            "max": 8.9,
            "length_correlation": -0.33725682516002636,
            "length_correlation_p": 0.0001653736965072848
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.898333333333333,
            "median": 6.01,
            "stdev": 0.7923673001678894,
            "ci95": 0.14177249841626385,
            "min": 4.15,
            "max": 7.97,
            "length_correlation": 0.056892980981558344,
            "length_correlation_p": 0.5370973528766104
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.17375,
            "median": 7.005,
            "stdev": 0.831464297580636,
            "ci95": 0.1487678388380668,
            "min": 5.44,
            "max": 8.97,
            "length_correlation": -0.046646071062285466,
            "length_correlation_p": 0.6129203817688949
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 7.61975,
            "median": 7.365,
            "stdev": 0.9667988089436136,
            "ci95": 0.17298225530099787,
            "min": 5.82,
            "max": 9.65,
            "length_correlation": 0.019698687124776917,
            "length_correlation_p": 0.8308976975260207
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 5.231166666666667,
            "median": 5.31,
            "stdev": 0.6235708815024184,
            "ci95": 0.11157098708073679,
            "min": 3.2,
            "max": 6.5,
            "length_correlation": -0.19543290673423538,
            "length_correlation_p": 0.03242561134317526
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 5.22525,
            "median": 5.385,
            "stdev": 0.7846692419916376,
            "ci95": 0.1403951410463046,
            "min": 2.66,
            "max": 7.07,
            "length_correlation": -0.2052268961925462,
            "length_correlation_p": 0.024537450025935038
        }
    },
    "calibrated_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.933457203636172,
            "median": 7.09433962264151,
            "stdev": 1.1634142900791502,
            "ci95": 0.20816122846406837,
            "min": 3.392857142857141,
            "max": 9.330188679245282,
            "length_correlation": -0.046903231389699235,
            "length_correlation_p": 0.6109615638450614
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 4.675820669341757,
            "median": 4.642857142857144,
            "stdev": 1.5576269538711691,
            "ci95": 0.2786948234790107,
            "min": 0.8901098901098901,
            "max": 8.235849056603774,
            "length_correlation": -0.09339125928422264,
            "length_correlation_p": 0.3103150576061891
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 6.005679383509572,
            "median": 6.235294117647059,
            "stdev": 1.5990721447785954,
            "ci95": 0.2861103090259785,
            "min": 2.3406593406593403,
            "max": 8.962264150943398,
            "length_correlation": 0.06951225095968495,
            "length_correlation_p": 0.4506021618165176
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 6.5705302004691575,
            "median": 6.88235294117647,
            "stdev": 1.240933100853631,
            "ci95": 0.2220311035528399,
            "min": 2.7692307692307683,
            "max": 9.11320754716981,
            "length_correlation": -0.22257927118656187,
            "length_correlation_p": 0.014547715397202957
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.175641076459612,
            "median": 5.029411764705881,
            "stdev": 1.5861616489109183,
            "ci95": 0.28380032821964585,
            "min": 2.4505494505494507,
            "max": 8.377358490566037,
            "length_correlation": -0.07670857046768864,
            "length_correlation_p": 0.4049954273471114
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.286714522528896,
            "median": 4.428571428571428,
            "stdev": 1.550801488687802,
            "ci95": 0.27747359280518796,
            "min": 0.06593406593406598,
            "max": 8.056603773584905,
            "length_correlation": -0.12579686332032433,
            "length_correlation_p": 0.17098144946447966
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 3.304009103641456,
            "median": 2.972527472527472,
            "stdev": 1.2853486629406694,
            "ci95": 0.22997805593755832,
            "min": 0.0,
            "max": 6.88235294117647,
            "length_correlation": 0.12803359177656018,
            "length_correlation_p": 0.16343838510462166
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 2.70076222796811,
            "median": 2.5879120879120876,
            "stdev": 1.0643022599391367,
            "ci95": 0.1904278362189814,
            "min": 0.1868131868131867,
            "max": 6.38235294117647,
            "length_correlation": -0.18300976878217726,
            "length_correlation_p": 0.04542273062751666
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 2.1906660741219564,
            "median": 2.126373626373626,
            "stdev": 1.1018089094531445,
            "ci95": 0.19713862729743373,
            "min": 0.3626373626373626,
            "max": 5.2941176470588225,
            "length_correlation": 0.16260071571394102,
            "length_correlation_p": 0.07599930759629547
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.456082400304098,
            "median": 4.321428571428569,
            "stdev": 1.6701606302407694,
            "ci95": 0.298829652934372,
            "min": 0.758241758241758,
            "max": 8.68867924528302,
            "length_correlation": -0.0176929823520277,
            "length_correlation_p": 0.8478963256591515
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 4.092376627719302,
            "median": 3.8571428571428554,
            "stdev": 1.3521789437288145,
            "ci95": 0.2419355103595016,
            "min": 1.4285714285714282,
            "max": 7.433962264150943,
            "length_correlation": 0.10557343176762216,
            "length_correlation_p": 0.25113192486900476
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 6.83055863854976,
            "median": 7.0424528301886795,
            "stdev": 1.2217973818521264,
            "ci95": 0.21860728900211315,
            "min": 3.0,
            "max": 9.29245283018868,
            "length_correlation": -0.2576411135332974,
            "length_correlation_p": 0.004498635500208466
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.18456197428173,
            "median": 5.647058823529411,
            "stdev": 1.8103614135474975,
            "ci95": 0.3239147559227217,
            "min": 1.8131868131868134,
            "max": 8.415094339622641,
            "length_correlation": 0.05755286632945163,
            "length_correlation_p": 0.5323787565324618
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 7.527726137624861,
            "median": 7.504716981132075,
            "stdev": 1.0267578021653654,
            "ci95": 0.1837102803845298,
            "min": 3.7500000000000004,
            "max": 9.358490566037737,
            "length_correlation": -0.06198780276132321,
            "length_correlation_p": 0.5012131970501417
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 8.063526637069922,
            "median": 7.84433962264151,
            "stdev": 0.9539364543526576,
            "ci95": 0.17068088806197962,
            "min": 5.088235294117648,
            "max": 10.0,
            "length_correlation": 0.03583632449611133,
            "length_correlation_p": 0.6975845310359943
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 3.545890072284356,
            "median": 3.285714285714283,
            "stdev": 1.2577961300295923,
            "ci95": 0.22504828229890353,
            "min": 0.7692307692307694,
            "max": 7.028301886792453,
            "length_correlation": -0.16094135264591472,
            "length_correlation_p": 0.07908207472036732
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 3.654270590674586,
            "median": 3.553571428571428,
            "stdev": 1.5456677619116008,
            "ci95": 0.27655505253845264,
            "min": 0.17582417582417595,
            "max": 7.566037735849057,
            "length_correlation": -0.14295285954337214,
            "length_correlation_p": 0.11933040982188287
        }
    },
    "length_correlation": {
        "raw": {
            "pearson_corr": -0.06905637735602667,
            "pearson_p": 0.3052310000539606
        },
        "calibrated": {
            "pearson_corr": -0.048852699660190464,
            "pearson_p": 0.31061056788201225
        }
    },
    "raw_cross_model_stats": {
        "anova_f": 165.38402656505033,
        "anova_p": 0.0,
        "kw_stat": 1228.2408498746188,
        "kw_p": 1.291822841166611e-251,
        "std_dev_across_models": 0.8414975038986546,
        "pearson_r": 0.970126515772653,
        "kendall_tau": 0.8764705882352941,
        "normalized_components": {
            "pearson_r": 0.9004217192421765,
            "kendall_tau": 0.8627450980392157,
            "anova_f": 0.4725257901858581,
            "kw_stat": 0.6823560277081215,
            "std_dev": 0.32365288611486714,
            "ci99_overlap_magnitude_sum_norm": 0.7991311152192639,
            "ci99_overlap_magnitude_pct_norm": 0.5657504588857449,
            "raw_score_range_norm": 0.3240416666666667,
            "kendall_tau_bootstrapped": 0.8628872549019606
        }
    },
    "calibrated_cross_model_stats": {
        "anova_f": 191.0070580095099,
        "anova_p": 0.0,
        "kw_stat": 1228.2408498746188,
        "kw_p": 1.291822841166611e-251,
        "std_dev_across_models": 1.6824091262309262,
        "pearson_r": 0.965162453208992,
        "kendall_tau": 0.888235294117647,
        "normalized_components": {
            "pearson_r": 0.8838748440299732,
            "kendall_tau": 0.8758169934640523,
            "anova_f": 0.5457344514557426,
            "kw_stat": 0.6823560277081215,
            "std_dev": 0.6470804331657408,
            "ci99_overlap_magnitude_sum_norm": 0.6225648109721948,
            "ci99_overlap_magnitude_pct_norm": 0.5754483693295194,
            "calibrated_score_range_norm": 0.5872860562947965,
            "kendall_tau_bootstrapped": 0.86578431372549
        }
    },
    "separability_metrics": {
        "raw": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": false,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": false,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gemma-7b-it": false,
                "gemma-7b-it__gemma-2b-it": false
            },
            "adjacent_overlap_fraction": 0.6875,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.18826529660945557,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.1482225641099495,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.49475086351000197,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.36929595203231713,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.2992908913407293,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.1474260537954395,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.4559408294354128,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": 0.325265990823727,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.3967532753150529,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.3791889241132953,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.3806906538203805,
                "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.15986831683671632,
                "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.43987931318638473,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.37533196700693416,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.15462451999497517,
                "gemma-7b-it__gemma-2b-it": 0.12404191582073487
            },
            "ci99_overlap_magnitude_sum": 4.838837327751507,
            "ci99_overlap_scale_factor": 1.5,
            "ci99_overlap_percentage_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.0,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.0,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.8246327980785022,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.5556314874021752,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.3533145536076235,
                "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.0,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.8956684401163487,
                "Mistral-Large-Instruct-2411__claude-3-haiku-20240307": 0.463845654446872,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.7330704357819138,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.6398365101318872,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.8887627058860195,
                "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.08491965490777953,
                "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.8973463264086147,
                "databricks/dbrx-instruct__Llama-2-13b-chat-hf": 0.6109640910603449,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.0,
                "gemma-7b-it__gemma-2b-it": 0.0
            },
            "ci99_overlap_percentage_adjacent_avg": 0.43424954111425507,
            "average_cohens_d_adjacent": 0.27554709741565364,
            "cohens_d_norm": 0.688867743539134,
            "emd": {
                "average": 1.0162463235294117,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 1.0338333333333334,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.45000000000000007,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.22216666666666668,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 0.8120833333333333,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 1.240416666666667,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 1.6571666666666667,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 1.9777500000000001,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 2.3695000000000004,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 1.1205000000000003,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 1.26725,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.08333333333333326,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 0.8505,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.4250833333333335,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 0.8709166666666668,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 1.517666666666667,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 1.5235833333333333,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 0.5838333333333332,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 0.8116666666666666,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.22175000000000006,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.20725000000000005,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 0.6233333333333333,
                    "claude-3-haiku-20240307__gemma-7b-it": 0.9439166666666667,
                    "claude-3-haiku-20240307__gemma-2b-it": 1.3356666666666666,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.113,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.2415833333333333,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 0.9683333333333333,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.2506666666666667,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 1.4587499999999998,
                    "claude-3-haiku-20240307__DeepSeek-R1": 1.90475,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 0.48383333333333345,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.48974999999999996,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.2586666666666666,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.36424999999999996,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 0.7904166666666665,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 1.2071666666666665,
                    "claude-3-opus-20240229__gemma-7b-it": 1.5277500000000002,
                    "claude-3-opus-20240229__gemma-2b-it": 1.9194999999999998,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 0.6704999999999999,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 0.8172499999999998,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.38450000000000006,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.4005000000000001,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 0.8749166666666668,
                    "claude-3-opus-20240229__DeepSeek-R1": 1.3209166666666667,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 1.0676666666666668,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 1.0735833333333331,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 0.5899166666666666,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 1.01825,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 1.435,
                    "gemini-1.5-pro-001__gemma-7b-it": 1.7555833333333335,
                    "gemini-1.5-pro-001__gemma-2b-it": 2.147333333333333,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 0.8983333333333334,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 1.0450833333333334,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.15850000000000003,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.6283333333333334,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.6470833333333333,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.0930833333333334,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 1.2955,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 1.3014166666666664,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.42833333333333345,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 0.8450833333333334,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 1.1656666666666666,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 1.5574166666666667,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.3139166666666668,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.4551666666666667,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 0.7465833333333333,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.15025,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 1.2369999999999997,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 1.6829999999999998,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 0.7055833333333335,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 0.7115,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.41691666666666666,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 0.7391666666666667,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 1.1335833333333332,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.14058333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.136,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 1.1749166666666668,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.38991666666666674,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 1.6653333333333336,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 2.1113333333333335,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.2879166666666667,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.2888333333333333,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.3234166666666668,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.7178333333333333,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.5366666666666666,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.38991666666666663,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 1.5916666666666668,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 0.8066666666666666,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 2.0820833333333337,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 2.528083333333333,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.17433333333333328,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.19508333333333333,
                    "gemma-7b-it__gemma-2b-it": 0.4004166666666666,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 0.8572500000000001,
                    "gemma-7b-it__c4ai-command-r-08-2024": 0.7105000000000001,
                    "gemma-7b-it__gemini-1.5-pro-002": 1.9122499999999998,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 1.1272499999999999,
                    "gemma-7b-it__gpt-4o-2024-11-20": 2.4026666666666667,
                    "gemma-7b-it__DeepSeek-R1": 2.848666666666667,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.4600833333333333,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.4590000000000001,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 1.2489999999999999,
                    "gemma-2b-it__c4ai-command-r-08-2024": 1.10225,
                    "gemma-2b-it__gemini-1.5-pro-002": 2.3040000000000003,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 1.5189999999999997,
                    "gemma-2b-it__gpt-4o-2024-11-20": 2.7944166666666668,
                    "gemma-2b-it__DeepSeek-R1": 3.240416666666667,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.8518333333333332,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.8525833333333335,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.17074999999999993,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 1.055,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.2856666666666666,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 1.5454166666666667,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 1.9914166666666668,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.3973333333333333,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.40308333333333324,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 1.2017499999999999,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.4225833333333333,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 1.6921666666666666,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 2.1381666666666668,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.25041666666666673,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.2648333333333333,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 0.7849999999999999,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.49075,
                    "gemini-1.5-pro-002__DeepSeek-R1": 0.9364166666666668,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 1.4521666666666666,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 1.4580833333333332,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 1.2754166666666666,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 1.7214166666666668,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 0.6671666666666667,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 0.6730833333333333,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.44599999999999995,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 1.9425833333333338,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 1.9485000000000003,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 2.3885833333333335,
                    "DeepSeek-R1__databricks/dbrx-instruct": 2.3945,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.13908333333333328
                }
            },
            "average_ci95": 0.13106646590649373,
            "modulated_ci95": 0.8463506347773375
        },
        "calibrated": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": false,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": false,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__Mistral-Large-Instruct-2411": false,
                "Mistral-Large-Instruct-2411__Llama-3-70b-chat-hf": true,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gemma-7b-it": false,
                "gemma-7b-it__gemma-2b-it": false
            },
            "adjacent_overlap_fraction": 0.6875,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.16281007958819504,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.17822656273437865,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.7383893327106623,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.6086011158569473,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.43684730105106784,
                "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.38142374245137933,
                "Mistral-Large-Instruct-2411__Llama-3-70b-chat-hf": 1.1189100027320809,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.6090251246547851,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.9187345395304476,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.966697521285742,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.8295721984008622,
                "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.5839933396334334,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": 0.8804291004607236,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.6551115129254921,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.22549839198081223,
                "gemma-7b-it__gemma-2b-it": 0.25391281589751813
            },
            "ci99_overlap_magnitude_sum": 9.548182681894529,
            "ci99_overlap_scale_factor": 1.5,
            "ci99_overlap_percentage_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.0,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.0,
                "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.8170233571514224,
                "gemini-1.5-pro-002__gemini-1.5-pro-001": 0.5510010464023747,
                "gemini-1.5-pro-001__claude-3-opus-20240229": 0.15665125509407235,
                "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.0,
                "Mistral-Large-Instruct-2411__Llama-3-70b-chat-hf": 0.9380787275516304,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.3238904773990455,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.7113474926047949,
                "Mixtral-8x22B-Instruct-v0.1__Mixtral-8x7B-Instruct-v0.1": 0.7774433121561455,
                "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.7186646562845035,
                "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.3586486769336308,
                "databricks/dbrx-instruct__gpt-3.5-turbo-0125": 0.8444937971731754,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.5955832919768955,
                "Llama-2-13b-chat-hf__gemma-7b-it": 0.0,
                "gemma-7b-it__gemma-2b-it": 0.0
            },
            "ci99_overlap_percentage_adjacent_avg": 0.4245516306704807,
            "average_cohens_d_adjacent": 0.28267978676072664,
            "cohens_d_norm": 0.7066994669018165,
            "emd": {
                "average": 2.0505021309727685,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 2.2576365342944147,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.9277778201265995,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.3629270031670143,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 1.7578161271765602,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 2.6467426811072765,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 3.6294480999947156,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 4.232694975668061,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 4.742791129514216,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 2.477374803332074,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 2.8410805759168696,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.14069915702129898,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 1.7488952293544415,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.5944261666930923,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 1.1300694334337509,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 3.3875671313518154,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 3.2791866129615856,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 1.3298587141678153,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 1.8947095311274005,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.49982040711785464,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.3910669311265871,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 1.3718115657003005,
                    "claude-3-haiku-20240307__gemma-7b-it": 1.9750584413736467,
                    "claude-3-haiku-20240307__gemma-2b-it": 2.4851545952198,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.25190623056189093,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.5924184005968137,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 2.1547379692080026,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.5897394734381418,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 2.851905468283105,
                    "claude-3-haiku-20240307__DeepSeek-R1": 3.387705967728166,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 1.1299305970574007,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 1.021550078667171,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.5939388672740505,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.8324192594309132,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 1.7189648609806771,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 2.701670279868116,
                    "claude-3-opus-20240229__gemma-7b-it": 3.304917155541461,
                    "claude-3-opus-20240229__gemma-2b-it": 3.8150133093876155,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 1.5495969832054741,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 1.9133027557902702,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.8248792550401876,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.8211174092278422,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 1.5220467541152893,
                    "claude-3-opus-20240229__DeepSeek-R1": 2.0578472535603503,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 2.4597893112252165,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 2.3514087928349863,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 1.394889124009546,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 2.2838156779402623,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 3.2665210968277014,
                    "gemini-1.5-pro-001__gemma-7b-it": 3.869767972501048,
                    "gemini-1.5-pro-001__gemma-2b-it": 4.379864126347202,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 2.114447800165059,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 2.4781535727498554,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.2665760571282214,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 1.3859682261874273,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.9571959371557041,
                    "gemini-1.5-pro-001__DeepSeek-R1": 1.492996436600765,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 3.024640128184801,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 2.9162596097945714,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.8889265539307161,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 1.871631972818155,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 2.4748788484915014,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 2.9849750023376553,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.7247473554007963,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 1.0832644487403091,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 1.6549175620901484,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.28513861277457275,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 2.35208506116525,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 2.8878855606103118,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 1.6297510041752554,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 1.5213704857850252,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.9828885690705891,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 1.5879669465754374,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 2.1009935033519938,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.24317740158472678,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.3159496164213147,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 2.543844116020864,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.8978474517528348,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 3.2410116150959665,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 3.7768121145410274,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.752546061966151,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.6380490185914717,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.6063604287868996,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 1.1193869855634562,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 1.1520732966626421,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.7883675240778458,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 3.5265495349083036,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 1.8805528706402739,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 4.223717033983405,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 4.759517533428466,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.2929583226614301,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.4178439046155472,
                    "gemma-7b-it__gemma-2b-it": 0.5275465955613012,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 1.7553201723359884,
                    "gemma-7b-it__c4ai-command-r-08-2024": 1.3916143997511923,
                    "gemma-7b-it__gemini-1.5-pro-002": 4.129796410581649,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 2.48379974631362,
                    "gemma-7b-it__gpt-4o-2024-11-20": 4.826963909656751,
                    "gemma-7b-it__DeepSeek-R1": 5.362764409101812,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.845127844316246,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.9588197180178313,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 2.265416326182142,
                    "gemma-2b-it__c4ai-command-r-08-2024": 1.9017105535973462,
                    "gemma-2b-it__gemini-1.5-pro-002": 4.639892564427803,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 2.9938959001597736,
                    "gemma-2b-it__gpt-4o-2024-11-20": 5.337060063502905,
                    "gemma-2b-it__DeepSeek-R1": 5.872860562947965,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 1.3552239981624,
                    "gemma-2b-it__databricks/dbrx-instruct": 1.470930523878637,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.39213983851886186,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 2.3744762382456615,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.7449440843100669,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 3.0716437373207635,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 3.607444236765825,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.9103754782028926,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.8018118096295122,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 2.7381820108304575,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 1.0985956029726842,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 3.43534950990556,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 3.9711500093506205,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.5464865554349463,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.4481226852134177,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 1.6459966642680297,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.6974819644839068,
                    "gemini-1.5-pro-002__DeepSeek-R1": 1.2329679985201627,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 3.2846685662654043,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 3.1762880478751736,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 2.3431641633431313,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 2.8789646627881926,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 1.6386719019973743,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 1.5302913836071443,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.5358004994450609,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 3.981836065340506,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 3.873455546950276,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 4.517636564785567,
                    "DeepSeek-R1__databricks/dbrx-instruct": 4.4092560463953365,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.27184205685176827
                }
            },
            "average_ci95": 0.24194691861783993,
            "modulated_ci95": 0.553243687511645
        }
    },
    "iteration_stability": {
        "raw": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.748833333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09356422333824423
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 5.715,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.17368633925684654
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.2988333333333335,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1281490560072743
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.526666666666666,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.12005583191906086
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.93675,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.042274236966633676
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 5.508416666666666,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1161229592572746
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 5.091666666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.10201953788912742
                },
                "gemma-7b-it": {
                    "mean_iter_score": 4.771083333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.07034221902796194
                },
                "gemma-2b-it": {
                    "mean_iter_score": 4.379333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.15914454471049633
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 5.628333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.043876404694196236
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 5.481583333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11518143899469607
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 6.683333333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.18109466523831605
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.898333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.06273345288688562
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.17375,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08661055876097833
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 7.61975,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08449054845234313
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 5.231166666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.12253752259795553
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 5.22525,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1413925288769608
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    }
                },
                "average_kendall_tau": 0.9294117647058823
            },
            "randomized_average_kendall_tau_by_item": 0.9177323529411764
        },
        "calibrated": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.933457203636172,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11238158310405767
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 4.675820669341757,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.4190080400294
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 6.005679383509572,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.26202569828407374
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 6.5705302004691575,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.25142003830366305
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.175641076459612,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1120595295910236
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 4.286714522528896,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2919457716079414
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 3.304009103641456,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2269270131897274
                },
                "gemma-7b-it": {
                    "mean_iter_score": 2.70076222796811,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.1142181050459879
                },
                "gemma-2b-it": {
                    "mean_iter_score": 2.1906660741219564,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.23472161284112855
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.456082400304098,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.21209463277193139
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 4.092376627719302,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.28505672892812567
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 6.83055863854976,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3350004894405921
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.18456197428173,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.18864449405951447
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 7.527726137624861,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.08608950531019233
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 8.063526637069922,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.06399203338108192
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 3.545890072284356,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2495761784406335
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 3.654270590674586,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.4089344193984408
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9705882352941175,
                        "p_value": 8.546830053210383e-13
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9117647058823529,
                        "p_value": 3.8599058936360526e-10
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.9411764705882352,
                        "p_value": 2.628150241362193e-11
                    }
                },
                "average_kendall_tau": 0.938235294117647
            },
            "randomized_average_kendall_tau_by_item": 0.919470588235294
        }
    },
    "raw_score_range": 3.2404166666666665,
    "final_judgemark_score_elements_raw": {
        "norm_stability_between_iterations": 0.8628872549019606,
        "norm_correlation_with_lmsys_arena": 0.8627450980392157,
        "norm_std_dev_between_models": 0.32365288611486714,
        "norm_kruskall_wallis": 0.6823560277081215,
        "norm_ci99_adjacent_overlap": 0.5657504588857449,
        "norm_score_range": 0.3240416666666667,
        "norm_intra_model_ci95": 0.8463506347773375,
        "norm_earth_movers_distance": 0.2540615808823529
    },
    "final_judgemark_score_raw": 0.7036408876881515,
    "calibrated_score_range": 5.872860562947965,
    "final_judgemark_score_elements_calibrated": {
        "norm_stability_between_iterations": 0.86578431372549,
        "norm_correlation_with_lmsys_arena": 0.8758169934640523,
        "norm_std_dev_between_models": 0.6470804331657408,
        "norm_kruskall_wallis": 0.6823560277081215,
        "norm_ci99_adjacent_overlap": 0.5754483693295194,
        "norm_score_range": 0.5872860562947965,
        "norm_intra_model_ci95": 0.553243687511645,
        "norm_earth_movers_distance": 0.5126255327431921
    },
    "final_judgemark_score": 0.7095350168774708
}