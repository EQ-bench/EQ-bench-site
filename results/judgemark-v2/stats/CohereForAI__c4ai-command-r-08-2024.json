{
    "judge_model": "cohere/command-r-08-2024",
    "start_time": "2025-01-31T17:25:56.939587",
    "status": "completed",
    "samples_file": "data/judgemark_v2.1_samples.json",
    "prompts_file": "data/judge_prompts.json",
    "end_time": "2025-01-31T18:30:12.025126",
    "raw_score_distribution": {
        "count": 2040,
        "min": 3.57,
        "max": 9.66,
        "mean": 8.082,
        "median": 8.27,
        "stdev": 0.837,
        "p10": 7.11,
        "p25": 7.68,
        "p75": 8.62,
        "p90": 8.95
    },
    "calibration_config": {
        "method": "piecewise_landmark",
        "in_landmarks": [
            3.57,
            7.68,
            8.27,
            8.62,
            9.66
        ],
        "out_landmarks": [
            0,
            3,
            5,
            7,
            10
        ]
    },
    "calibrated_score_distribution": {
        "count": 2040,
        "min": 0.0,
        "max": 10.0,
        "mean": 5.107,
        "median": 5.0,
        "stdev": 2.125,
        "p10": 2.584,
        "p25": 3.0,
        "p75": 7.0,
        "p90": 7.952
    },
    "raw_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 8.440666666666667,
            "median": 8.52,
            "stdev": 0.6060850168244118,
            "ci95": 0.10844236892367197,
            "min": 5.86,
            "max": 9.56,
            "length_correlation": 0.05214997412084469
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 8.0425,
            "median": 8.195,
            "stdev": 0.6655259498441563,
            "ci95": 0.11907770127600074,
            "min": 5.54,
            "max": 9.16,
            "length_correlation": -0.05669334828041156
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 8.386,
            "median": 8.455,
            "stdev": 0.6204395297561508,
            "ci95": 0.11101071716501155,
            "min": 5.67,
            "max": 9.5,
            "length_correlation": -0.030279260197911204
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 8.37125,
            "median": 8.455,
            "stdev": 0.6176174912890814,
            "ci95": 0.11050579041700156,
            "min": 6.0,
            "max": 9.4,
            "length_correlation": 0.22997933598673337
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 8.174,
            "median": 8.29,
            "stdev": 0.6368335534422758,
            "ci95": 0.11394398018152535,
            "min": 5.04,
            "max": 9.16,
            "length_correlation": -0.005360385141086795
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 7.963666666666667,
            "median": 8.195,
            "stdev": 0.8219784835693574,
            "ci95": 0.14707061136337668,
            "min": 5.41,
            "max": 9.55,
            "length_correlation": -0.2106069832487962
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 7.6105,
            "median": 7.71,
            "stdev": 0.976410722575118,
            "ci95": 0.17470204486047486,
            "min": 4.11,
            "max": 9.55,
            "length_correlation": 0.05725575214779368
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 7.812083333333334,
            "median": 7.93,
            "stdev": 0.9639178596000919,
            "ci95": 0.17246678805978888,
            "min": 4.36,
            "max": 9.31,
            "length_correlation": 0.019803266828896292
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 7.7935,
            "median": 7.86,
            "stdev": 0.9170803599219765,
            "ci95": 0.1640864960569129,
            "min": 3.64,
            "max": 9.3,
            "length_correlation": 0.005448163565321536
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 7.959333333333333,
            "median": 8.114999999999998,
            "stdev": 0.7909941976577902,
            "ci95": 0.14152681920487142,
            "min": 3.93,
            "max": 9.34,
            "length_correlation": -0.05496080398365353
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 7.879,
            "median": 8.07,
            "stdev": 0.9762726234480396,
            "ci95": 0.17467733579149783,
            "min": 4.61,
            "max": 9.64,
            "length_correlation": -0.005821459935592639
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 8.294583333333334,
            "median": 8.34,
            "stdev": 0.6178791264041361,
            "ci95": 0.11055260287875619,
            "min": 4.93,
            "max": 9.47,
            "length_correlation": 0.16135461320719155
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 8.039166666666667,
            "median": 8.32,
            "stdev": 1.0013869233758363,
            "ci95": 0.17917085419639,
            "min": 3.57,
            "max": 9.28,
            "length_correlation": -0.1434394997043876
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 8.504833333333334,
            "median": 8.52,
            "stdev": 0.607473045822249,
            "ci95": 0.10869071882258363,
            "min": 5.89,
            "max": 9.66,
            "length_correlation": -0.10584876135762995
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 8.6115,
            "median": 8.614999999999998,
            "stdev": 0.44906934577069985,
            "ci95": 0.08034870078381515,
            "min": 7.39,
            "max": 9.65,
            "length_correlation": 0.14611531993308707
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 7.618916666666666,
            "median": 7.779999999999999,
            "stdev": 0.9701388584949604,
            "ci95": 0.17357986599193403,
            "min": 4.39,
            "max": 9.48,
            "length_correlation": -0.19625565952041846
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 7.890666666666666,
            "median": 7.9399999999999995,
            "stdev": 0.782832320856153,
            "ci95": 0.1400664741531654,
            "min": 5.11,
            "max": 9.55,
            "length_correlation": -0.07319535130457155
        }
    },
    "calibrated_model_stats": {
        "claude-3-5-sonnet-20240620": {
            "count": 120,
            "mean": 6.085375044637619,
            "median": 6.428571428571431,
            "stdev": 1.9787283732306,
            "ci95": 0.35403942729667437,
            "min": 1.671532846715329,
            "max": 9.711538461538463,
            "length_correlation": 0.055241183205275435
        },
        "claude-3-haiku-20240307": {
            "count": 120,
            "mean": 4.799175888186622,
            "median": 4.745762711864409,
            "stdev": 1.8037169493767362,
            "ci95": 0.32272591043916043,
            "min": 1.4379562043795624,
            "max": 8.557692307692308,
            "length_correlation": -0.04755431096337916
        },
        "claude-3-opus-20240229": {
            "count": 120,
            "mean": 5.9085947995929615,
            "median": 6.057142857142861,
            "stdev": 1.9399728591170105,
            "ci95": 0.34710518598948487,
            "min": 1.5328467153284673,
            "max": 9.538461538461538,
            "length_correlation": 0.006905749568671498
        },
        "gemini-1.5-pro-001": {
            "count": 120,
            "mean": 5.846187496856109,
            "median": 6.057142857142861,
            "stdev": 1.9836742118871868,
            "ci95": 0.35492435011335227,
            "min": 1.7737226277372269,
            "max": 9.250000000000002,
            "length_correlation": 0.21774409844857903
        },
        "Llama-3-70b-chat-hf": {
            "count": 120,
            "mean": 5.206476617762419,
            "median": 5.114285714285712,
            "stdev": 1.900622466627552,
            "ci95": 0.34006450743585315,
            "min": 1.0729927007299274,
            "max": 8.557692307692308,
            "length_correlation": 0.015722471297150833
        },
        "Mixtral-8x7B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.802161964648821,
            "median": 4.745762711864409,
            "stdev": 2.007677914223909,
            "ci95": 0.3592191573962833,
            "min": 1.3430656934306573,
            "max": 9.68269230769231,
            "length_correlation": -0.12747844652772028
        },
        "Llama-2-13b-chat-hf": {
            "count": 120,
            "mean": 3.9778861304012096,
            "median": 3.1016949152542383,
            "stdev": 1.998680838570055,
            "ci95": 0.3576093763091325,
            "min": 0.39416058394160625,
            "max": 9.68269230769231,
            "length_correlation": 0.03663764061280786
        },
        "gemma-7b-it": {
            "count": 120,
            "mean": 4.489934236270762,
            "median": 3.8474576271186445,
            "stdev": 2.1381214898162075,
            "ci95": 0.3825584744152371,
            "min": 0.5766423357664239,
            "max": 8.990384615384617,
            "length_correlation": -0.01521999902753902
        },
        "gemma-2b-it": {
            "count": 120,
            "mean": 4.321493293141352,
            "median": 3.6101694915254257,
            "stdev": 1.9976959021063,
            "ci95": 0.3574331488156225,
            "min": 0.05109489051094912,
            "max": 8.961538461538463,
            "length_correlation": 0.01403058204553775
        },
        "Mixtral-8x22B-Instruct-v0.1": {
            "count": 120,
            "mean": 4.68944037315009,
            "median": 4.474576271186439,
            "stdev": 2.003526263761943,
            "ci95": 0.35847633287737735,
            "min": 0.26277372262773746,
            "max": 9.076923076923077,
            "length_correlation": 0.010618927313500882
        },
        "c4ai-command-r-08-2024": {
            "count": 120,
            "mean": 4.64143522628553,
            "median": 4.3220338983050866,
            "stdev": 2.1499516428130483,
            "ci95": 0.3846751573559054,
            "min": 0.7591240875912413,
            "max": 9.942307692307693,
            "length_correlation": -0.08105571325717185
        },
        "gemini-1.5-pro-002": {
            "count": 120,
            "mean": 5.559801841267729,
            "median": 5.400000000000002,
            "stdev": 1.931232319243802,
            "ci95": 0.3455413049773972,
            "min": 0.9927007299270074,
            "max": 9.451923076923078,
            "length_correlation": 0.18264877746033703
        },
        "Mistral-Large-Instruct-2411": {
            "count": 120,
            "mean": 5.1348614027473225,
            "median": 5.28571428571429,
            "stdev": 2.14607572623915,
            "ci95": 0.3839816678893182,
            "min": 0.0,
            "max": 8.903846153846153,
            "length_correlation": -0.14144498186171203
        },
        "gpt-4o-2024-11-20": {
            "count": 120,
            "mean": 6.304042292839539,
            "median": 6.42857142857143,
            "stdev": 1.9368416375027855,
            "ci95": 0.3465449393573363,
            "min": 1.6934306569343067,
            "max": 10.0,
            "length_correlation": -0.12868927350928064
        },
        "DeepSeek-R1": {
            "count": 120,
            "mean": 6.634180696926895,
            "median": 6.9714285714285715,
            "stdev": 1.7023304367651357,
            "ci95": 0.3045855616443363,
            "min": 2.788321167883212,
            "max": 9.971153846153847,
            "length_correlation": 0.14459743185715918
        },
        "gpt-3.5-turbo-0125": {
            "count": 120,
            "mean": 3.927438697766625,
            "median": 3.338983050847458,
            "stdev": 1.886833325345228,
            "ci95": 0.33759731701772805,
            "min": 0.5985401459854014,
            "max": 9.480769230769232,
            "length_correlation": -0.12772902568067124
        },
        "databricks/dbrx-instruct": {
            "count": 120,
            "mean": 4.485869283609295,
            "median": 3.881355932203391,
            "stdev": 2.059653442465409,
            "ci95": 0.3685187593532813,
            "min": 1.1240875912408763,
            "max": 9.68269230769231,
            "length_correlation": 0.0019149998356498932
        }
    },
    "raw_cross_model_stats": {
        "anova_f": 18.51889028267589,
        "anova_p": 1.1633015106525469e-49,
        "kw_stat": 291.3686029859868,
        "kw_p": 1.558835457348983e-52,
        "std_dev_across_models": 0.29908144201553705,
        "pearson_r": 0.8350687171329042,
        "kendall_tau": 0.6499999999999999,
        "normalized_components": {
            "pearson_r": 0.45022905710968075,
            "kendall_tau": 0.611111111111111,
            "anova_f": 0.05291111509335969,
            "kw_stat": 0.1942457353239912,
            "std_dev": 0.13594611000706228,
            "ci99_overlap_magnitude_sum_norm": 0.7113897502258317,
            "raw_score_range_norm": 0.12512499999999993,
            "kendall_tau_bootstrapped": 0.42079411764705865
        }
    },
    "calibrated_cross_model_stats": {
        "anova_f": 20.624716997532673,
        "anova_p": 1.0264084312752292e-55,
        "kw_stat": 291.3686029859868,
        "kw_p": 1.558835457348983e-52,
        "std_dev_across_models": 0.7954172841342049,
        "pearson_r": 0.8531005267382236,
        "kendall_tau": 0.6941176470588235,
        "normalized_components": {
            "pearson_r": 0.510335089127412,
            "kendall_tau": 0.6601307189542484,
            "anova_f": 0.05892776285009335,
            "kw_stat": 0.1942457353239912,
            "std_dev": 0.3615533109700931,
            "ci99_overlap_magnitude_sum_norm": 0.24639166756631148,
            "calibrated_score_range_norm": 0.3383427498950337,
            "kendall_tau_bootstrapped": 0.4270931372549018
        }
    },
    "separability_metrics": {
        "raw": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": true,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": true,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__Llama-3-70b-chat-hf": true,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__gemma-7b-it": true,
                "gemma-7b-it__gemma-2b-it": true,
                "gemma-2b-it__gpt-3.5-turbo-0125": true,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": true
            },
            "adjacent_overlap_fraction": 1.0,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.2659863510996914,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 0.36386734112939934,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.3779407490742557,
                "claude-3-opus-20240229__gemini-1.5-pro-001": 0.4219250342726273,
                "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.3591052878588332,
                "gemini-1.5-pro-002__Llama-3-70b-chat-hf": 0.3219663175798857,
                "Llama-3-70b-chat-hf__claude-3-haiku-20240307": 0.32785515979122426,
                "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.4694752535907618,
                "Mistral-Large-Instruct-2411__Mixtral-8x7B-Instruct-v0.1": 0.567619127822641,
                "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.5579830532846577,
                "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.4864376114311453,
                "databricks/dbrx-instruct__c4ai-command-r-08-2024": 0.5522255029109671,
                "c4ai-command-r-08-2024__gemma-7b-it": 0.6174078283111051,
                "gemma-7b-it__gemma-2b-it": 0.6448634611310178,
                "gemma-2b-it__gpt-3.5-turbo-0125": 0.49105766936169637,
                "gpt-3.5-turbo-0125__Llama-2-13b-chat-hf": 0.6781507454784661
            },
            "ci99_overlap_magnitude_sum": 7.503866494128375,
            "ci99_overlap_scale_factor": 1.5,
            "average_cohens_d_adjacent": 0.08856085766814203,
            "emd": {
                "average": 0.3818713235294117,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 0.39816666666666667,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.06300000000000007,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.07674999999999996,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 0.2676666666666667,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 0.47700000000000004,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 0.8301666666666665,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 0.6289166666666668,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 0.6471666666666667,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 0.4813333333333334,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 0.5678333333333334,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.16025000000000006,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 0.4015000000000001,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.08299999999999995,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 0.1735,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 0.82175,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 0.5529999999999999,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 0.3434999999999999,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 0.3287500000000001,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.13983333333333325,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.125,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 0.4405,
                    "claude-3-haiku-20240307__gemma-7b-it": 0.2695833333333334,
                    "claude-3-haiku-20240307__gemma-2b-it": 0.25600000000000006,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.12299999999999996,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.22466666666666674,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 0.26225,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.20900000000000002,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 0.4623333333333334,
                    "claude-3-haiku-20240307__DeepSeek-R1": 0.569,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 0.4357500000000001,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.19766666666666663,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.03874999999999996,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.22166666666666668,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 0.42316666666666664,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 0.7763333333333333,
                    "claude-3-opus-20240229__gemma-7b-it": 0.5739166666666666,
                    "claude-3-opus-20240229__gemma-2b-it": 0.5924999999999999,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 0.42666666666666664,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 0.5121666666666667,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.12225,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.347,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 0.12533333333333344,
                    "claude-3-opus-20240229__DeepSeek-R1": 0.22550000000000006,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 0.7670833333333333,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 0.49849999999999994,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 0.2062500000000001,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 0.41008333333333336,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 0.76325,
                    "gemini-1.5-pro-001__gemma-7b-it": 0.5591666666666668,
                    "gemini-1.5-pro-001__gemma-2b-it": 0.57775,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 0.4119166666666669,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 0.49958333333333343,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.10500000000000012,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.33208333333333345,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.14258333333333334,
                    "gemini-1.5-pro-001__DeepSeek-R1": 0.24025,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 0.7536666666666667,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 0.4854166666666666,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.22483333333333336,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 0.5700000000000001,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 0.3717499999999999,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 0.385,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.2213333333333333,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.31700000000000006,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 0.12241666666666669,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.17300000000000015,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 0.3346666666666668,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 0.43750000000000006,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 0.5640833333333334,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 0.31133333333333324,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.35333333333333344,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 0.17141666666666672,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 0.17383333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.12749999999999997,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.13150000000000012,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 0.34024999999999994,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.1978333333333333,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 0.5411666666666667,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 0.6478333333333334,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.34725000000000006,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.17299999999999993,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.22325,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.20333333333333342,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.3555,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.29600000000000004,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 0.6854166666666667,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 0.4625,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 0.8943333333333334,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 1.0010000000000001,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.10774999999999998,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.28016666666666673,
                    "gemma-7b-it__gemma-2b-it": 0.08574999999999997,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 0.16841666666666671,
                    "gemma-7b-it__c4ai-command-r-08-2024": 0.10625000000000002,
                    "gemma-7b-it__gemini-1.5-pro-002": 0.4825,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 0.26758333333333334,
                    "gemma-7b-it__gpt-4o-2024-11-20": 0.69275,
                    "gemma-7b-it__DeepSeek-R1": 0.7994166666666669,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.1995,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.13308333333333344,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 0.16916666666666652,
                    "gemma-2b-it__c4ai-command-r-08-2024": 0.13816666666666666,
                    "gemma-2b-it__gemini-1.5-pro-002": 0.5010833333333333,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 0.29833333333333334,
                    "gemma-2b-it__gpt-4o-2024-11-20": 0.7113333333333334,
                    "gemma-2b-it__DeepSeek-R1": 0.8180000000000001,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.19608333333333333,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.13266666666666668,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.14783333333333343,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 0.33525000000000005,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.21716666666666673,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 0.5455000000000001,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 0.6521666666666668,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.3510833333333333,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.13583333333333325,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 0.42108333333333337,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.21600000000000008,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 0.6258333333333334,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 0.7325,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.2669166666666667,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.18699999999999992,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 0.25658333333333333,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.2254166666666667,
                    "gemini-1.5-pro-002__DeepSeek-R1": 0.31725000000000003,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 0.6758333333333334,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 0.4084166666666666,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 0.4656666666666668,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 0.5723333333333334,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 0.45875,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 0.30433333333333334,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.12766666666666662,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 0.8859166666666667,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 0.6141666666666666,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 0.9925833333333334,
                    "DeepSeek-R1__databricks/dbrx-instruct": 0.7208333333333332,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.27175000000000005
                }
            },
            "average_ci95": 0.13705411000745754,
            "modulated_ci95": 0.2214021441703551
        },
        "calibrated": {
            "ci99_overlap_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": true,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": true,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": true,
                "claude-3-opus-20240229__gemini-1.5-pro-001": true,
                "gemini-1.5-pro-001__gemini-1.5-pro-002": true,
                "gemini-1.5-pro-002__Llama-3-70b-chat-hf": true,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": true,
                "Mistral-Large-Instruct-2411__Mixtral-8x7B-Instruct-v0.1": true,
                "Mixtral-8x7B-Instruct-v0.1__claude-3-haiku-20240307": true,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": true,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": true,
                "c4ai-command-r-08-2024__gemma-7b-it": true,
                "gemma-7b-it__databricks/dbrx-instruct": true,
                "databricks/dbrx-instruct__gemma-2b-it": true,
                "gemma-2b-it__Llama-2-13b-chat-hf": true,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": true
            },
            "adjacent_overlap_fraction": 1.0,
            "ci99_overlap_magnitude_adjacent": {
                "DeepSeek-R1__gpt-4o-2024-11-20": 0.9534338088574792,
                "gpt-4o-2024-11-20__claude-3-5-sonnet-20240620": 1.1623932680498505,
                "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 1.205384684236937,
                "claude-3-opus-20240229__gemini-1.5-pro-001": 1.3215020730671236,
                "gemini-1.5-pro-001__gemini-1.5-pro-002": 1.0944408448037084,
                "gemini-1.5-pro-002__Llama-3-70b-chat-hf": 0.9982080996815519,
                "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 1.340736923495193,
                "Mistral-Large-Instruct-2411__Mixtral-8x7B-Instruct-v0.1": 1.1323708151099519,
                "Mixtral-8x7B-Instruct-v0.1__claude-3-haiku-20240307": 1.2723778425362564,
                "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 1.2331170614772322,
                "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 1.413327310491273,
                "c4ai-command-r-08-2024__gemma-7b-it": 1.3609450850242792,
                "gemma-7b-it__databricks/dbrx-instruct": 1.4529205396678577,
                "databricks/dbrx-instruct__gemma-2b-it": 1.2666915080234116,
                "gemma-2b-it__Llama-2-13b-chat-hf": 1.0659546914689995,
                "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 1.3200120872847987
            },
            "ci99_overlap_magnitude_sum": 19.5938166432759,
            "ci99_overlap_scale_factor": 1.5,
            "average_cohens_d_adjacent": 0.08627710120257132,
            "emd": {
                "average": 0.9896579800183954,
                "pairs": {
                    "claude-3-5-sonnet-20240620__claude-3-haiku-20240307": 1.286199156450997,
                    "claude-3-5-sonnet-20240620__claude-3-opus-20240229": 0.2003480686186676,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-001": 0.25208175515564457,
                    "claude-3-5-sonnet-20240620__Llama-3-70b-chat-hf": 0.879628353882499,
                    "claude-3-5-sonnet-20240620__Mixtral-8x7B-Instruct-v0.1": 1.2832130799887977,
                    "claude-3-5-sonnet-20240620__Llama-2-13b-chat-hf": 2.10748891423641,
                    "claude-3-5-sonnet-20240620__gemma-7b-it": 1.5964023468283959,
                    "claude-3-5-sonnet-20240620__gemma-2b-it": 1.763881751496267,
                    "claude-3-5-sonnet-20240620__Mixtral-8x22B-Instruct-v0.1": 1.3959346714875298,
                    "claude-3-5-sonnet-20240620__c4ai-command-r-08-2024": 1.4617282798905502,
                    "claude-3-5-sonnet-20240620__gemini-1.5-pro-002": 0.5481237367780887,
                    "claude-3-5-sonnet-20240620__Mistral-Large-Instruct-2411": 0.9505136418902969,
                    "claude-3-5-sonnet-20240620__gpt-4o-2024-11-20": 0.24556733108740397,
                    "claude-3-5-sonnet-20240620__DeepSeek-R1": 0.5564979599815831,
                    "claude-3-5-sonnet-20240620__gpt-3.5-turbo-0125": 2.1579363468709944,
                    "claude-3-5-sonnet-20240620__databricks/dbrx-instruct": 1.6081596071821704,
                    "claude-3-haiku-20240307__claude-3-opus-20240229": 1.1094189114063386,
                    "claude-3-haiku-20240307__gemini-1.5-pro-001": 1.0470116086694867,
                    "claude-3-haiku-20240307__Llama-3-70b-chat-hf": 0.4133834546366245,
                    "claude-3-haiku-20240307__Mixtral-8x7B-Instruct-v0.1": 0.20914816641356923,
                    "claude-3-haiku-20240307__Llama-2-13b-chat-hf": 0.8458089885546438,
                    "claude-3-haiku-20240307__gemma-7b-it": 0.4783442160184245,
                    "claude-3-haiku-20240307__gemma-2b-it": 0.5007045730672486,
                    "claude-3-haiku-20240307__Mixtral-8x22B-Instruct-v0.1": 0.2839543193465777,
                    "claude-3-haiku-20240307__c4ai-command-r-08-2024": 0.3742699659303954,
                    "claude-3-haiku-20240307__gemini-1.5-pro-002": 0.7680468776553151,
                    "claude-3-haiku-20240307__Mistral-Large-Instruct-2411": 0.49067334911057836,
                    "claude-3-haiku-20240307__gpt-4o-2024-11-20": 1.5048664046529168,
                    "claude-3-haiku-20240307__DeepSeek-R1": 1.8350048087402722,
                    "claude-3-haiku-20240307__gpt-3.5-turbo-0125": 0.9068333442661514,
                    "claude-3-haiku-20240307__databricks/dbrx-instruct": 0.43842672168649544,
                    "claude-3-opus-20240229__gemini-1.5-pro-001": 0.11344009597767468,
                    "claude-3-opus-20240229__Llama-3-70b-chat-hf": 0.709174142901101,
                    "claude-3-opus-20240229__Mixtral-8x7B-Instruct-v0.1": 1.1088366810979857,
                    "claude-3-opus-20240229__Llama-2-13b-chat-hf": 1.9331125153455981,
                    "claude-3-opus-20240229__gemma-7b-it": 1.4186605633221991,
                    "claude-3-opus-20240229__gemma-2b-it": 1.587101506451609,
                    "claude-3-opus-20240229__Mixtral-8x22B-Instruct-v0.1": 1.2191544264428718,
                    "claude-3-opus-20240229__c4ai-command-r-08-2024": 1.2820634194612766,
                    "claude-3-opus-20240229__gemini-1.5-pro-002": 0.3795586798300056,
                    "claude-3-opus-20240229__Mistral-Large-Instruct-2411": 0.7742141660764079,
                    "claude-3-opus-20240229__gpt-4o-2024-11-20": 0.40019201879402333,
                    "claude-3-opus-20240229__DeepSeek-R1": 0.7255858973339337,
                    "claude-3-opus-20240229__gpt-3.5-turbo-0125": 1.9811561018263362,
                    "claude-3-opus-20240229__databricks/dbrx-instruct": 1.4318601313682815,
                    "gemini-1.5-pro-001__Llama-3-70b-chat-hf": 0.6462802221593829,
                    "gemini-1.5-pro-001__Mixtral-8x7B-Instruct-v0.1": 1.0512370706688259,
                    "gemini-1.5-pro-001__Llama-2-13b-chat-hf": 1.8755129049164379,
                    "gemini-1.5-pro-001__gemma-7b-it": 1.356253260585347,
                    "gemini-1.5-pro-001__gemma-2b-it": 1.5246942037147568,
                    "gemini-1.5-pro-001__Mixtral-8x22B-Instruct-v0.1": 1.1567471237060196,
                    "gemini-1.5-pro-001__c4ai-command-r-08-2024": 1.2259061167244245,
                    "gemini-1.5-pro-001__gemini-1.5-pro-002": 0.31784036268177407,
                    "gemini-1.5-pro-001__Mistral-Large-Instruct-2411": 0.7113260941087867,
                    "gemini-1.5-pro-001__gpt-4o-2024-11-20": 0.46442413904912355,
                    "gemini-1.5-pro-001__DeepSeek-R1": 0.7879932000707858,
                    "gemini-1.5-pro-001__gpt-3.5-turbo-0125": 1.922594952935638,
                    "gemini-1.5-pro-001__databricks/dbrx-instruct": 1.3742605209391217,
                    "Llama-3-70b-chat-hf__Mixtral-8x7B-Instruct-v0.1": 0.432854331197072,
                    "Llama-3-70b-chat-hf__Llama-2-13b-chat-hf": 1.2473404873612104,
                    "Llama-3-70b-chat-hf__gemma-7b-it": 0.7449077661070422,
                    "Llama-3-70b-chat-hf__gemma-2b-it": 0.8979640938518366,
                    "Llama-3-70b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.5362670138430994,
                    "Llama-3-70b-chat-hf__c4ai-command-r-08-2024": 0.6285029299384275,
                    "Llama-3-70b-chat-hf__gemini-1.5-pro-002": 0.3546634230186906,
                    "Llama-3-70b-chat-hf__Mistral-Large-Instruct-2411": 0.20893004707569265,
                    "Llama-3-70b-chat-hf__gpt-4o-2024-11-20": 1.1003637286051,
                    "Llama-3-70b-chat-hf__DeepSeek-R1": 1.4277040791644748,
                    "Llama-3-70b-chat-hf__gpt-3.5-turbo-0125": 1.3049994584573332,
                    "Llama-3-70b-chat-hf__databricks/dbrx-instruct": 0.7988627618154867,
                    "Mixtral-8x7B-Instruct-v0.1__Llama-2-13b-chat-hf": 0.8247566034783815,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-7b-it": 0.3687730413376062,
                    "Mixtral-8x7B-Instruct-v0.1__gemma-2b-it": 0.484781529452444,
                    "Mixtral-8x7B-Instruct-v0.1__Mixtral-8x22B-Instruct-v0.1": 0.22107761807556128,
                    "Mixtral-8x7B-Instruct-v0.1__c4ai-command-r-08-2024": 0.2627627133372221,
                    "Mixtral-8x7B-Instruct-v0.1__gemini-1.5-pro-002": 0.7673254465234548,
                    "Mixtral-8x7B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.4316899396893675,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-4o-2024-11-20": 1.5018803281907176,
                    "Mixtral-8x7B-Instruct-v0.1__DeepSeek-R1": 1.832018732278073,
                    "Mixtral-8x7B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.8819348053437353,
                    "Mixtral-8x7B-Instruct-v0.1__databricks/dbrx-instruct": 0.4445890501205671,
                    "Llama-2-13b-chat-hf__gemma-7b-it": 0.5364819445369677,
                    "Llama-2-13b-chat-hf__gemma-2b-it": 0.37029979796379997,
                    "Llama-2-13b-chat-hf__Mixtral-8x22B-Instruct-v0.1": 0.724320946847701,
                    "Llama-2-13b-chat-hf__c4ai-command-r-08-2024": 0.6836220885850512,
                    "Llama-2-13b-chat-hf__gemini-1.5-pro-002": 1.5857618647126728,
                    "Llama-2-13b-chat-hf__Mistral-Large-Instruct-2411": 1.1913672337909942,
                    "Llama-2-13b-chat-hf__gpt-4o-2024-11-20": 2.3261561624383296,
                    "Llama-2-13b-chat-hf__DeepSeek-R1": 2.6562945665256854,
                    "Llama-2-13b-chat-hf__gpt-3.5-turbo-0125": 0.19328060259877008,
                    "Llama-2-13b-chat-hf__databricks/dbrx-instruct": 0.5079831532080856,
                    "gemma-7b-it__gemma-2b-it": 0.22401597477226892,
                    "gemma-7b-it__Mixtral-8x22B-Instruct-v0.1": 0.25644057713493584,
                    "gemma-7b-it__c4ai-command-r-08-2024": 0.23260244588085444,
                    "gemma-7b-it__gemini-1.5-pro-002": 1.0698676049969664,
                    "gemma-7b-it__Mistral-Large-Instruct-2411": 0.6770030133790499,
                    "gemma-7b-it__gpt-4o-2024-11-20": 1.8141080565687775,
                    "gemma-7b-it__DeepSeek-R1": 2.1442464606561327,
                    "gemma-7b-it__gpt-3.5-turbo-0125": 0.5732233599527613,
                    "gemma-7b-it__databricks/dbrx-instruct": 0.23678125024074895,
                    "gemma-2b-it__Mixtral-8x22B-Instruct-v0.1": 0.3743304320581475,
                    "gemma-2b-it__c4ai-command-r-08-2024": 0.3583847555286067,
                    "gemma-2b-it__gemini-1.5-pro-002": 1.2383085481263758,
                    "gemma-2b-it__Mistral-Large-Instruct-2411": 0.8525291614495039,
                    "gemma-2b-it__gpt-4o-2024-11-20": 1.9825489996981869,
                    "gemma-2b-it__DeepSeek-R1": 2.3126874037855423,
                    "gemma-2b-it__gpt-3.5-turbo-0125": 0.42375350048421634,
                    "gemma-2b-it__databricks/dbrx-instruct": 0.20375169373700275,
                    "Mixtral-8x22B-Instruct-v0.1__c4ai-command-r-08-2024": 0.21607820266973768,
                    "Mixtral-8x22B-Instruct-v0.1__gemini-1.5-pro-002": 0.8703614681176388,
                    "Mixtral-8x22B-Instruct-v0.1__Mistral-Large-Instruct-2411": 0.5478190269769823,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-4o-2024-11-20": 1.6146019196894499,
                    "Mixtral-8x22B-Instruct-v0.1__DeepSeek-R1": 1.9447403237768053,
                    "Mixtral-8x22B-Instruct-v0.1__gpt-3.5-turbo-0125": 0.7762516285932717,
                    "Mixtral-8x22B-Instruct-v0.1__databricks/dbrx-instruct": 0.32406168471204655,
                    "c4ai-command-r-08-2024__gemini-1.5-pro-002": 0.9342319995975821,
                    "c4ai-command-r-08-2024__Mistral-Large-Instruct-2411": 0.5582411212493643,
                    "c4ai-command-r-08-2024__gpt-4o-2024-11-20": 1.6626070665540085,
                    "c4ai-command-r-08-2024__DeepSeek-R1": 1.9927454706413639,
                    "c4ai-command-r-08-2024__gpt-3.5-turbo-0125": 0.7189843630687841,
                    "c4ai-command-r-08-2024__databricks/dbrx-instruct": 0.3260536301712226,
                    "gemini-1.5-pro-002__Mistral-Large-Instruct-2411": 0.4283058231357905,
                    "gemini-1.5-pro-002__gpt-4o-2024-11-20": 0.7553110111825164,
                    "gemini-1.5-pro-002__DeepSeek-R1": 1.075340394120705,
                    "gemini-1.5-pro-002__gpt-3.5-turbo-0125": 1.6328439127318723,
                    "gemini-1.5-pro-002__databricks/dbrx-instruct": 1.080449261757254,
                    "Mistral-Large-Instruct-2411__gpt-4o-2024-11-20": 1.1691808900922167,
                    "Mistral-Large-Instruct-2411__DeepSeek-R1": 1.4993192941795723,
                    "Mistral-Large-Instruct-2411__gpt-3.5-turbo-0125": 1.242707189352773,
                    "Mistral-Large-Instruct-2411__databricks/dbrx-instruct": 0.7903909119510539,
                    "gpt-4o-2024-11-20__DeepSeek-R1": 0.39071532716427876,
                    "gpt-4o-2024-11-20__gpt-3.5-turbo-0125": 2.3766035950729143,
                    "gpt-4o-2024-11-20__databricks/dbrx-instruct": 1.818173009230244,
                    "DeepSeek-R1__gpt-3.5-turbo-0125": 2.7067419991602697,
                    "DeepSeek-R1__databricks/dbrx-instruct": 2.1483114133175993,
                    "gpt-3.5-turbo-0125__databricks/dbrx-instruct": 0.5584305858426701
                }
            },
            "average_ci95": 0.3532706222754989,
            "modulated_ci95": 0.06954608592665444
        }
    },
    "iteration_stability": {
        "raw": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 8.440666666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09403737436667294
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 8.0425,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11453832449349746
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 8.386000000000001,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.13557659786588835
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 8.37125,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.09532837982468792
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 8.174,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.14350851697528066
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 7.963666666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.16609326362686203
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 7.6105,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.18661520868115536
                },
                "gemma-7b-it": {
                    "mean_iter_score": 7.812083333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.13596874640887138
                },
                "gemma-2b-it": {
                    "mean_iter_score": 7.7935,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.12261519527004411
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 7.959333333333333,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.15695023096510546
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 7.879,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2272181709771957
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 8.294583333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.037598943543077565
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 8.039166666666667,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.16398022407866444
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 8.504833333333334,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.05232683080621486
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 8.6115,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.041022182346194765
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 7.618916666666666,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.04349936142570866
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 7.890666666666666,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.11693053493420803
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.5294117647058822,
                        "p_value": 0.0024551285640838213
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.5735294117647058,
                        "p_value": 0.0009013347020841902
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6029411764705882,
                        "p_value": 0.0004320184609575974
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6029411764705882,
                        "p_value": 0.0004320184609575974
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7499999999999999,
                        "p_value": 3.7189175256511566e-06
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6911764705882353,
                        "p_value": 3.209019424470449e-05
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7499999999999999,
                        "p_value": 3.7189175256511566e-06
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.676470588235294,
                        "p_value": 5.18722751399025e-05
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7941176470588235,
                        "p_value": 5.454070925094403e-07
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7058823529411764,
                        "p_value": 1.9425366308238382e-05
                    }
                },
                "average_kendall_tau": 0.6676470588235294
            },
            "randomized_average_kendall_tau_by_item": 0.6524764705882352
        },
        "calibrated": {
            "scoring_stability": {
                "claude-3-5-sonnet-20240620": {
                    "mean_iter_score": 6.085375044637619,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.42041336541442126
                },
                "claude-3-haiku-20240307": {
                    "mean_iter_score": 4.799175888186623,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.24827557412989912
                },
                "claude-3-opus-20240229": {
                    "mean_iter_score": 5.908594799592961,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.4010935590247477
                },
                "gemini-1.5-pro-001": {
                    "mean_iter_score": 5.846187496856109,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.30563072774798217
                },
                "Llama-3-70b-chat-hf": {
                    "mean_iter_score": 5.206476617762419,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.34087519312229125
                },
                "Mixtral-8x7B-Instruct-v0.1": {
                    "mean_iter_score": 4.802161964648821,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3243315898270376
                },
                "Llama-2-13b-chat-hf": {
                    "mean_iter_score": 3.9778861304012096,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.23374723413878995
                },
                "gemma-7b-it": {
                    "mean_iter_score": 4.489934236270762,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.41127510560125907
                },
                "gemma-2b-it": {
                    "mean_iter_score": 4.321493293141352,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2879583974457906
                },
                "Mixtral-8x22B-Instruct-v0.1": {
                    "mean_iter_score": 4.689440373150089,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.43465346417127837
                },
                "c4ai-command-r-08-2024": {
                    "mean_iter_score": 4.641435226285531,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.36396927339744956
                },
                "gemini-1.5-pro-002": {
                    "mean_iter_score": 5.559801841267729,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.24896193772212905
                },
                "Mistral-Large-Instruct-2411": {
                    "mean_iter_score": 5.1348614027473225,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.3353192466118859
                },
                "gpt-4o-2024-11-20": {
                    "mean_iter_score": 6.304042292839539,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2515238127089477
                },
                "DeepSeek-R1": {
                    "mean_iter_score": 6.634180696926895,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.15166266213426843
                },
                "gpt-3.5-turbo-0125": {
                    "mean_iter_score": 3.927438697766625,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.2102076794826437
                },
                "databricks/dbrx-instruct": {
                    "mean_iter_score": 4.485869283609295,
                    "iteration_count": 5,
                    "stdev_across_iters": 0.21198084980084453
                }
            },
            "ranking_stability": {
                "pairwise_correlation": {
                    "1__vs__2": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6323529411764706,
                        "p_value": 0.00019489090240009966
                    },
                    "1__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6323529411764706,
                        "p_value": 0.00019489090240009966
                    },
                    "1__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7058823529411764,
                        "p_value": 1.9425366308238382e-05
                    },
                    "1__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6176470588235293,
                        "p_value": 0.0002924937719584528
                    },
                    "2__vs__3": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6470588235294118,
                        "p_value": 0.00012768041939830013
                    },
                    "2__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7499999999999999,
                        "p_value": 3.7189175256511566e-06
                    },
                    "2__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7794117647058824,
                        "p_value": 1.0700241221269077e-06
                    },
                    "3__vs__4": {
                        "common_model_count": 17,
                        "kendall_tau": 0.6323529411764706,
                        "p_value": 0.00019489090240009966
                    },
                    "3__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.7205882352941176,
                        "p_value": 1.148789053319355e-05
                    },
                    "4__vs__5": {
                        "common_model_count": 17,
                        "kendall_tau": 0.764705882352941,
                        "p_value": 2.0270077800034225e-06
                    }
                },
                "average_kendall_tau": 0.6882352941176471
            },
            "randomized_average_kendall_tau_by_item": 0.6562558823529411
        }
    },
    "raw_score_range": 1.0009999999999994,
    "final_judgemark_score_elements_raw": {
        "norm_stability_between_iterations": 0.42079411764705865,
        "norm_correlation_with_lmsys_arena": 0.611111111111111,
        "norm_std_dev_between_models": 0.13594611000706228,
        "norm_kruskall_wallis": 0.1942457353239912,
        "norm_ci99_adjacent_overlap": 0.7113897502258317,
        "norm_score_range": 0.12512499999999993,
        "norm_intra_model_ci95": 0.2214021441703551,
        "norm_earth_movers_distance": 0.09546783088235293
    },
    "final_judgemark_score_raw": 0.336826045971872,
    "calibrated_score_range": 2.7067419991602697,
    "final_judgemark_score_elements_calibrated": {
        "norm_stability_between_iterations": 0.4270931372549018,
        "norm_correlation_with_lmsys_arena": 0.6601307189542484,
        "norm_std_dev_between_models": 0.3615533109700931,
        "norm_kruskall_wallis": 0.1942457353239912,
        "norm_ci99_adjacent_overlap": 0.24639166756631148,
        "norm_score_range": 0.3383427498950337,
        "norm_intra_model_ci95": 0.06954608592665444,
        "norm_earth_movers_distance": {
            "pearson_r": 0.510335089127412,
            "kendall_tau": 0.6601307189542484,
            "anova_f": 0.05892776285009335,
            "kw_stat": 0.1942457353239912,
            "std_dev": 0.3615533109700931,
            "ci99_overlap_magnitude_sum_norm": 0.24639166756631148,
            "calibrated_score_range_norm": 0.3383427498950337,
            "kendall_tau_bootstrapped": 0.4270931372549018
        }
    },
    "final_judgemark_score": 0.3431477587778231
}